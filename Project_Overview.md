# Final Project Guidelines

## Overview

For the Final Project, you will work with your group to collaboratively solve or analyze a problem using advanced ML methodologies. Your solution must incorporate:

- Transformer models
- Natural Language Processing (NLP) techniques
- Other tools learned throughout the course
- **At least one new technology not covered in class**

---

## Specific Requirements

### Core Tasks

- Identify a problem worth solving or analyzing.
- Find a dataset large enough to train a high-accuracy ML model or neural network.
- Evaluate the trained model(s) using testing data. Include metrics, calculations, or visualizations to assess performance.

### Required Tools

Use **at least two** of the following:

- `scikit-learn`
- `Keras`
- `TensorFlow`
- `Hugging Face`
- `spaCy` or `Natural Language Toolkit (NLTK)`
- `LangChain`
- `OpenAI`

### Additional Technology (Use at least one)

Choose **one or more** of the following:

- Valence Aware Dictionary for Sentiment Reasoning (VADER)
- Whisper (OpenAI’s automatic speech recognition system)
- DALL·E (OpenAI’s text-to-image model)
- Other OpenAI capabilities (e.g., Text-to-speech, GPT-4 with vision)
- PyTorch

---

## Industry Focus Examples

### Finance

- Customer service chatbot with multilingual recommendations
- Deep learning model for stock price prediction
- NLP/transformer-based earnings call summarizer

### Healthcare

- Transformer model for multilingual image captioning
- Deep learning model for mole classification (malignant vs. benign)
- NLP for de-identifying medical data

### Custom Projects

- Spam detection and filtering using AI
- Sentiment analysis on social media or product reviews
- Language translation model using transformers

---

## Group Collaboration

### Communication & Tools

- Establish communication methods (e.g., Slack, phone numbers)
- Use **GitHub Projects** for agile task tracking
- Define internal milestones:

  - Project ideation  
  - Data fetching  
  - Data exploration  
  - Data transformation  
  - Data analysis  
  - Data cleaning/preprocessing  
  - Model testing  
  - AI tool integration  
  - Documentation  
  - Presentation prep  

- Complete at least 50% of your project by the end of **Week 1**

---

## Support and Resources

- Instructional support via classes, office hours, learning assistants, and tutors
- Use available resources as needed to aid collaboration and technical execution

---

## Grading Rubric

### Model Implementation (25 Points)

- Jupyter notebook describes extraction, cleaning, preprocessing, and transformation (10 pts)
- Python script to initialize/train/evaluate or load pre-trained model (10 pts)
- Uses one new technology not covered in class (5 pts)

### Model Optimization (25 Points)

- Documentation of optimization process and impact (15 pts)
- Final performance displayed at script end (10 pts)

### GitHub Documentation (25 Points)

- Clean repo with proper `.gitignore` (10 pts)
- Customized, polished `README.md` (15 pts)

### Presentation (25 Points)

- Executive summary/project goals (5 pts)
- Data collection/cleanup/evaluation summary (5 pts)
- Approach to goal (5 pts)
- Future development/next steps (3 pts)
- Results and conclusions (3 pts)
- Effective slides (2 pts)
- Clean, professional slide design (2 pts)

---

## Letter Grade Conversion

| Grade | Points  |
|-------|---------|
| A (+/-) | 90+     |
| B (+/-) | 80–89   |
| C (+/-) | 70–79   |
| D (+/-) | 60–69   |
| F (+/-) | < 60    |

---

## Project Guidelines

### Collaboration

- Group projects are a chance to learn collaborative problem-solving and workflow strategies

### Project Proposal

Your proposal should include:

- Field of interest and dataset type
- Key questions you want to answer
- Data source(s)

**Example:**

> The aim of our project is to uncover patterns in credit card fraud. We’ll examine relationships between transaction types and location, purchase prices and times of day, purchase trends over the course of a year, and other related relationships derived from the data.

---

## Finding Data

Recommended sources:

- [UC Irvine ML Repository](https://archive.ics.uci.edu/ml/index.php)
- [data.world](https://data.world/)
- [Kaggle](https://www.kaggle.com/)
- [Data.gov](https://data.gov/)
- [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets)

### Data Usage Guidelines

- Ensure copyright and fair use
- Document dataset usage
- Confirm legal collection methods
- Use manageable-sized datasets

---

## Data Cleanup and Analysis

### Workflow

1. **Exploration and Cleanup**
   - Use a dedicated Jupyter notebook
   - Document every step
2. **Analysis**
   - Use a second Jupyter notebook
   - Apply techniques: aggregation, correlation, comparison, summary statistics, sentiment, time series
   - Visualize your findings early and often

---

## Presentation Guidelines

### Format

- Total Time: 10 minutes (7 min presentation, 3 min Q&A)

### Content

1. **Executive Summary**
   - Overview and industry context
2. **Data Process**
   - Source, rationale, collection, cleanup, exploration
3. **Approach**
   - Code demonstrations
   - Insights and challenges
4. **Results**
   - Visuals and explanations
   - What worked, what didn’t
5. **Next Steps**
   - Potential future work

### Requirements

- All group members must submit their GitHub repo URL on presentation day
- Rehearse ahead of time for clarity and timing

---
