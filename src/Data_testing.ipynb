{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import DataImporter\n",
    "from models.modelhelper import ModelHelper\n",
    "import numpy as np\n",
    "\n",
    "data_importer = DataImporter()\n",
    "data_importer.import_data()\n",
    "\n",
    "ds_train = data_importer.get_train_data()\n",
    "ds_test = data_importer.get_test_data()\n",
    "ds_validation = data_importer.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb019e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.info()\n",
    "print('\\n')\n",
    "ds_test.info()\n",
    "print('\\n')\n",
    "ds_validation.info()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns from each dataset\n",
    "columns_to_drop = ['id', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'context']\n",
    "\n",
    "ds_train = ds_train.drop(columns=columns_to_drop)\n",
    "ds_test = ds_test.drop(columns=columns_to_drop) \n",
    "ds_validation = ds_validation.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head())\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head())\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5811c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_false(ds_train, ds_test, ds_validation):\n",
    "    \"\"\"\n",
    "    Combines the 'false_counts' and 'pants_on_fire_counts' columns into a single 'false_counts' column,\n",
    "    and combines the 'barely_true' column into the 'half_true' column.\n",
    "    Drops the 'pants_on_fire_counts' and 'barely_true' columns from each dataset.\n",
    "\n",
    "    Parameters:\n",
    "        ds_train (pd.DataFrame): Training dataset\n",
    "        ds_test (pd.DataFrame): Test dataset\n",
    "        ds_validation (pd.DataFrame): Validation dataset\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated (ds_train, ds_test, ds_validation) DataFrames\n",
    "    \"\"\"\n",
    "    for ds in [ds_train, ds_test, ds_validation]:\n",
    "        # Combine false_counts and pants_on_fire_counts\n",
    "        ds['false_counts'] = ds['false_counts'] + ds['pants_on_fire_counts']\n",
    "        ds.drop('pants_on_fire_counts', axis=1, inplace=True)\n",
    "        \n",
    "        # Combine barely_true into half_true_counts\n",
    "        ds['half_true_counts'] = ds['half_true_counts'] + ds['barely_true_counts']\n",
    "        ds.drop('barely_true_counts', axis=1, inplace=True)\n",
    "        \n",
    "    return ds_train, ds_test, ds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_test, ds_validation = new_false(ds_train, ds_test, ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56856f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head())\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head())\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2485608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find longest statement\n",
    "longest_statement = ds_train.loc[ds_train['statement'].str.len().idxmax(), 'statement']\n",
    "# Get the labels for the longest statement\n",
    "longest_statement_label = ds_train.loc[ds_train['statement'].str.len().idxmax(), 'label']\n",
    "\n",
    "# Get word count by splitting on whitespace and counting tokens\n",
    "word_count = len(longest_statement.split())\n",
    "\n",
    "\n",
    "print(f\"Longest statement ({len(longest_statement)} characters):\")\n",
    "print(longest_statement)\n",
    "print(f'Longest statement word count: {word_count}')\n",
    "print(f\"Longest statement label: {longest_statement_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelHelper\n",
    "model_helper = ModelHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce61bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Vectorizer\n",
    "model_helper.create_vectorizer(ds_train['statement'], max_sequence_length=60)\n",
    "\n",
    "# Preprocess text data\n",
    "train_sequences = model_helper.preprocess_text(ds_train['statement'].tolist())\n",
    "test_sequences = model_helper.preprocess_text(ds_test['statement'].tolist())\n",
    "val_sequences = model_helper.preprocess_text(ds_validation['statement'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa49bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get truthfulness columns\n",
    "truthfulness_columns = model_helper.truthfulness_columns\n",
    "truthfulness_columns.remove('pants_on_fire_counts')\n",
    "truthfulness_columns.remove('barely_true_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43075b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw count values for training\n",
    "train_labels = model_helper.normalize_counts(ds_train)\n",
    "test_labels = model_helper.normalize_counts(ds_test)\n",
    "val_labels = model_helper.normalize_counts(ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dcc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text classification model\n",
    "vocab_size = 10000  # Matches max_tokens in preprocess_text\n",
    "embedding_dim = 100\n",
    "max_sequence_length = 200\n",
    "num_classes = len(truthfulness_columns)  # Number of truthfulness categories\n",
    "\n",
    "model = model_helper.create_text_classification_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim, \n",
    "    max_sequence_length=max_sequence_length,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a74105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset, val_dataset, test_dataset = model_helper.prepare_datasets(\n",
    "    train_sequences=train_sequences,\n",
    "    train_labels=train_labels,\n",
    "    val_sequences=val_sequences,\n",
    "    val_labels=val_labels,\n",
    "    test_sequences=test_sequences,\n",
    "    test_labels=test_labels,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf108f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir models/logs/fit\n",
    "\n",
    "# Train the model using ModelHelper's train_model method\n",
    "history = model_helper.train_model(\n",
    "    model=model,\n",
    "    train_data=train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=15,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = model.evaluate(test_dataset)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c615cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_helper.save_model(model, \"text_classification_model_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = model_helper.load_model(\"text_classification_model_final\")\n",
    "test_string = 'Barbara Buono by the numbers: As a Trenton politician, she voted to raise taxes 154 times. Under her, property taxes up 70 percent. Backed a 16 percent sales tax increase. Utilities, nursing homes, cell phones, parking lots, lottery wins, gyms She taxed them all. Architect of Corzines budget, she drove New Jersey $2 billion into debt. Barbara Buono by the numbers: taking New Jersey backwards.'\n",
    "print(model_helper.preprocess_text(test_string))\n",
    "prediction = loaded_model.predict(model_helper.preprocess_text(test_string))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test dataset\n",
    "print(test_dataset)\n",
    "predictions = loaded_model.predict(test_dataset)\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Predicted probabilities: {predictions[i]}\")\n",
    "    print(f\"Predicted class: {predicted_classes[i]}\")\n",
    "    print(f\"Actual class: {np.argmax(test_labels[i])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = model_helper.list_models()\n",
    "print(models_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
