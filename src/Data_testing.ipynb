{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a33157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import DataImporter\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "data_importer = DataImporter()\n",
    "data_importer.import_data()\n",
    "\n",
    "ds_train = data_importer.get_train_data()\n",
    "ds_test = data_importer.get_test_data()\n",
    "ds_validation = data_importer.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.info()\n",
    "print('\\n')\n",
    "ds_test.info()\n",
    "print('\\n')\n",
    "ds_validation.info()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5033e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns from each dataset\n",
    "columns_to_drop = ['id', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'context']\n",
    "\n",
    "ds_train = ds_train.drop(columns=columns_to_drop)\n",
    "ds_test = ds_test.drop(columns=columns_to_drop) \n",
    "ds_validation = ds_validation.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head())\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head())\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train['false_counts'] = ds_train['false_counts'] + ds_train['pants_on_fire_counts']\n",
    "ds_test['false_counts'] = ds_test['false_counts'] + ds_test['pants_on_fire_counts']\n",
    "ds_validation['false_counts'] = ds_validation['false_counts'] + ds_validation['pants_on_fire_counts']\n",
    "\n",
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head())\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head())\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449cf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.drop('pants_on_fire_counts', axis=1)\n",
    "ds_test = ds_test.drop('pants_on_fire_counts', axis=1) \n",
    "ds_validation = ds_validation.drop('pants_on_fire_counts', axis=1)\n",
    "\n",
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head())\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head())\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.modelhelper import ModelHelper\n",
    "import numpy as np\n",
    "\n",
    "# Initialize ModelHelper\n",
    "model_helper = ModelHelper()\n",
    "\n",
    "# Preprocess text data\n",
    "train_texts = ds_train['statement'].apply(model_helper.preprocess_text)\n",
    "test_texts = ds_test['statement'].apply(model_helper.preprocess_text)\n",
    "val_texts = ds_validation['statement'].apply(model_helper.preprocess_text)\n",
    "\n",
    "# Convert texts to sequences\n",
    "train_sequences = model_helper.preprocess_text(train_texts)\n",
    "test_sequences = model_helper.preprocess_text(test_texts)\n",
    "val_sequences = model_helper.preprocess_text(val_texts)\n",
    "\n",
    "# Get truthfulness columns\n",
    "truthfulness_columns = model_helper.truthfulness_columns\n",
    "truthfulness_columns.remove('pants_on_fire_counts')\n",
    "\n",
    "# Get the raw count values for training\n",
    "train_labels = model_helper.normalize_counts(ds_train)\n",
    "test_labels = model_helper.normalize_counts(ds_test)\n",
    "val_labels = model_helper.normalize_counts(ds_validation)\n",
    "\n",
    "# Create text classification model\n",
    "vocab_size = 10000  # Matches max_tokens in preprocess_text\n",
    "embedding_dim = 100\n",
    "max_sequence_length = 200\n",
    "num_classes = len(truthfulness_columns)  # Number of truthfulness categories\n",
    "\n",
    "model = model_helper.create_text_classification_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim, \n",
    "    max_sequence_length=max_sequence_length,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir models/logs/fit\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset, val_dataset, test_dataset = model_helper.prepare_datasets(\n",
    "    train_sequences=train_sequences,\n",
    "    train_labels=train_labels,\n",
    "    val_sequences=val_sequences,\n",
    "    val_labels=val_labels,\n",
    "    test_sequences=test_sequences,\n",
    "    test_labels=test_labels,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Train the model using ModelHelper's train_model method\n",
    "history = model_helper.train_model(\n",
    "    model=model,\n",
    "    train_data=train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=15,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = model.evaluate(test_dataset)\n",
    "print(test_metrics)\n",
    "\n",
    "# Save the model\n",
    "model_helper.save_model(model, \"text_classification_model_fourcol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = model_helper.load_model(\"text_classification_model_fourcol.keras\")\n",
    "\n",
    "# Make predictions on test dataset\n",
    "print(test_dataset)\n",
    "predictions = loaded_model.predict(test_dataset)\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Predicted probabilities: {predictions[i]}\")\n",
    "    print(f\"Predicted class: {predicted_classes[i]}\")\n",
    "    print(f\"Actual class: {np.argmax(test_labels[i])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e65deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'The president is a good man'\n",
    "prediction = loaded_model.predict(model_helper.preprocess_text(test_string))\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
