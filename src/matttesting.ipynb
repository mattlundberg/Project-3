{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import DataImporter\n",
    "from models.modelhelper import ModelHelper\n",
    "import numpy as np\n",
    "\n",
    "data_importer = DataImporter()\n",
    "data_importer.import_data()\n",
    "\n",
    "ds_train = data_importer.get_train_data()\n",
    "ds_test = data_importer.get_test_data()\n",
    "ds_validation = data_importer.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10269 entries, 0 to 10268\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    10269 non-null  object \n",
      " 1   label                 10269 non-null  int64  \n",
      " 2   statement             10269 non-null  object \n",
      " 3   subject               10269 non-null  object \n",
      " 4   speaker               10269 non-null  object \n",
      " 5   job_title             10269 non-null  object \n",
      " 6   state_info            10269 non-null  object \n",
      " 7   party_affiliation     10269 non-null  object \n",
      " 8   barely_true_counts    10269 non-null  float32\n",
      " 9   false_counts          10269 non-null  float32\n",
      " 10  half_true_counts      10269 non-null  float32\n",
      " 11  mostly_true_counts    10269 non-null  float32\n",
      " 12  pants_on_fire_counts  10269 non-null  float32\n",
      " 13  context               10269 non-null  object \n",
      "dtypes: float32(5), int64(1), object(8)\n",
      "memory usage: 922.7+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1283 entries, 0 to 1282\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1283 non-null   object \n",
      " 1   label                 1283 non-null   int64  \n",
      " 2   statement             1283 non-null   object \n",
      " 3   subject               1283 non-null   object \n",
      " 4   speaker               1283 non-null   object \n",
      " 5   job_title             1283 non-null   object \n",
      " 6   state_info            1283 non-null   object \n",
      " 7   party_affiliation     1283 non-null   object \n",
      " 8   barely_true_counts    1283 non-null   float32\n",
      " 9   false_counts          1283 non-null   float32\n",
      " 10  half_true_counts      1283 non-null   float32\n",
      " 11  mostly_true_counts    1283 non-null   float32\n",
      " 12  pants_on_fire_counts  1283 non-null   float32\n",
      " 13  context               1283 non-null   object \n",
      "dtypes: float32(5), int64(1), object(8)\n",
      "memory usage: 115.4+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1284 entries, 0 to 1283\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1284 non-null   object \n",
      " 1   label                 1284 non-null   int64  \n",
      " 2   statement             1284 non-null   object \n",
      " 3   subject               1284 non-null   object \n",
      " 4   speaker               1284 non-null   object \n",
      " 5   job_title             1284 non-null   object \n",
      " 6   state_info            1284 non-null   object \n",
      " 7   party_affiliation     1284 non-null   object \n",
      " 8   barely_true_counts    1284 non-null   float32\n",
      " 9   false_counts          1284 non-null   float32\n",
      " 10  half_true_counts      1284 non-null   float32\n",
      " 11  mostly_true_counts    1284 non-null   float32\n",
      " 12  pants_on_fire_counts  1284 non-null   float32\n",
      " 13  context               1284 non-null   object \n",
      "dtypes: float32(5), int64(1), object(8)\n",
      "memory usage: 115.5+ KB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_train.info()\n",
    "print('\\n')\n",
    "ds_test.info()\n",
    "print('\\n')\n",
    "ds_validation.info()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  \\\n",
       "0      0  Says the Annies List political group supports ...   \n",
       "1      1  When did the decline of coal start? It started...   \n",
       "2      2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3      0  Health care reform legislation is likely to ma...   \n",
       "4      1  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker party_affiliation  \\\n",
       "0                            abortion    dwayne-bohac        republican   \n",
       "1  energy,history,job-accomplishments  scott-surovell          democrat   \n",
       "2                      foreign-policy    barack-obama          democrat   \n",
       "3                         health-care    blog-posting              none   \n",
       "4                        economy,jobs   charlie-crist          democrat   \n",
       "\n",
       "   barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "0                 0.0           1.0               0.0                 0.0   \n",
       "1                 0.0           0.0               1.0                 1.0   \n",
       "2                70.0          71.0             160.0               163.0   \n",
       "3                 7.0          19.0               3.0                 5.0   \n",
       "4                15.0           9.0              20.0                19.0   \n",
       "\n",
       "   pants_on_fire_counts  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   9.0  \n",
       "3                  44.0  \n",
       "4                   2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>republican</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>republican</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>republican</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  \\\n",
       "0      3  Building a wall on the U.S.-Mexico border will...   \n",
       "1      0  Wisconsin is on pace to double the number of l...   \n",
       "2      0  Says John McCain has done nothing to help the ...   \n",
       "3      1  Suzanne Bonamici supports a plan that will cut...   \n",
       "4      5  When asked by a reporter whether hes at the ce...   \n",
       "\n",
       "                                             subject  \\\n",
       "0                                        immigration   \n",
       "1                                               jobs   \n",
       "2                    military,veterans,voting-record   \n",
       "3  medicare,message-machine-2012,campaign-adverti...   \n",
       "4  campaign-finance,legal-issues,campaign-adverti...   \n",
       "\n",
       "                            speaker party_affiliation  barely_true_counts  \\\n",
       "0                        rick-perry        republican                30.0   \n",
       "1                 katrina-shankland          democrat                 2.0   \n",
       "2                      donald-trump        republican                63.0   \n",
       "3                     rob-cornilles        republican                 1.0   \n",
       "4  state-democratic-party-wisconsin          democrat                 5.0   \n",
       "\n",
       "   false_counts  half_true_counts  mostly_true_counts  pants_on_fire_counts  \n",
       "0          30.0              42.0                23.0                  18.0  \n",
       "1           1.0               0.0                 0.0                   0.0  \n",
       "2         114.0              51.0                37.0                  61.0  \n",
       "3           1.0               3.0                 1.0                   1.0  \n",
       "4           7.0               2.0                 2.0                   7.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>vicky-hartzler</td>\n",
       "      <td>republican</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>obama-birth-certificate,religion</td>\n",
       "      <td>chain-email</td>\n",
       "      <td>none</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>campaign-finance,congress,taxes</td>\n",
       "      <td>earl-blumenauer</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>poverty</td>\n",
       "      <td>jim-francesconi</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>economy,stimulus</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  \\\n",
       "0      4  We have less Americans working now than in the...   \n",
       "1      5  When Obama was sworn into office, he DID NOT u...   \n",
       "2      0  Says Having organizations parading as being so...   \n",
       "3      1     Says nearly half of Oregons children are poor.   \n",
       "4      1  On attacks by Republicans that various program...   \n",
       "\n",
       "                            subject          speaker party_affiliation  \\\n",
       "0                      economy,jobs   vicky-hartzler        republican   \n",
       "1  obama-birth-certificate,religion      chain-email              none   \n",
       "2   campaign-finance,congress,taxes  earl-blumenauer          democrat   \n",
       "3                           poverty  jim-francesconi              none   \n",
       "4                  economy,stimulus     barack-obama          democrat   \n",
       "\n",
       "   barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "0                 1.0           0.0               1.0                 0.0   \n",
       "1                11.0          43.0               8.0                 5.0   \n",
       "2                 0.0           1.0               1.0                 1.0   \n",
       "3                 0.0           1.0               1.0                 1.0   \n",
       "4                70.0          71.0             160.0               163.0   \n",
       "\n",
       "   pants_on_fire_counts  \n",
       "0                   0.0  \n",
       "1                 105.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   9.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop specified columns from each dataset\n",
    "columns_to_drop = ['id',  'job_title', 'state_info', 'context']\n",
    "\n",
    "ds_train = ds_train.drop(columns=columns_to_drop)\n",
    "ds_test = ds_test.drop(columns=columns_to_drop) \n",
    "ds_validation = ds_validation.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head())\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head())\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest statement (395 characters):\n",
      "Barbara Buono by the numbers: As a Trenton politician, she voted to raise taxes 154 times. Under her, property taxes up 70 percent. Backed a 16 percent sales tax increase. Utilities, nursing homes, cell phones, parking lots, lottery wins, gyms She taxed them all. Architect of Corzines budget, she drove New Jersey $2 billion into debt. Barbara Buono by the numbers: taking New Jersey backwards.\n",
      "Longest statement word count: 65\n",
      "Longest statement label: 2\n"
     ]
    }
   ],
   "source": [
    "# Find longest statement\n",
    "longest_statement = ds_train.loc[ds_train['statement'].str.len().idxmax(), 'statement']\n",
    "# Get the labels for the longest statement\n",
    "longest_statement_label = ds_train.loc[ds_train['statement'].str.len().idxmax(), 'label']\n",
    "\n",
    "# Get word count by splitting on whitespace and counting tokens\n",
    "word_count = len(longest_statement.split())\n",
    "\n",
    "\n",
    "print(f\"Longest statement ({len(longest_statement)} characters):\")\n",
    "print(longest_statement)\n",
    "print(f'Longest statement word count: {word_count}')\n",
    "print(f\"Longest statement label: {longest_statement_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data and Model ready\n",
    "## Load model_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelHelper\n",
    "model_helper = ModelHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vectorizor and start preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Vectorizer\n",
    "model_helper.create_vectorizer(ds_train['statement'], max_sequence_length=60)\n",
    "\n",
    "# Preprocess text data\n",
    "train_sequences = model_helper.preprocess_text(ds_train['statement'].tolist())\n",
    "test_sequences = model_helper.preprocess_text(ds_test['statement'].tolist())\n",
    "val_sequences = model_helper.preprocess_text(ds_validation['statement'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sequence Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get truthfulness columns\n",
    "truthfulness_columns = model_helper.truthfulness_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw count values for training\n",
    "train_labels = model_helper.normalize_counts(ds_train)\n",
    "test_labels = model_helper.normalize_counts(ds_test)\n",
    "val_labels = model_helper.normalize_counts(ds_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text classification model\n",
    "vocab_size = 10000  # Matches max_tokens in preprocess_text\n",
    "embedding_dim = 100\n",
    "max_sequence_length = 200\n",
    "num_classes = len(truthfulness_columns)  # Number of truthfulness categories\n",
    "\n",
    "model = model_helper.create_text_classification_model(\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset, val_dataset, test_dataset = model_helper.prepare_datasets(\n",
    "    train_sequences=train_sequences,\n",
    "    train_labels=train_labels,\n",
    "    val_sequences=val_sequences,\n",
    "    val_labels=val_labels,\n",
    "    test_sequences=test_sequences,\n",
    "    test_labels=test_labels,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14640), started 4 days, 23:36:49 ago. (Use '!kill 14640' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2f44e761a924c1b2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2f44e761a924c1b2\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.2949 - accuracy: 0.2633 - categorical_accuracy: 0.2633 - precision: 0.6474 - recall: 0.0032 - val_loss: 2.2744 - val_accuracy: 0.2508 - val_categorical_accuracy: 0.2508 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 2/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.2661 - accuracy: 0.2787 - categorical_accuracy: 0.2787 - precision: 0.6158 - recall: 0.0031 - val_loss: 2.2543 - val_accuracy: 0.2430 - val_categorical_accuracy: 0.2430 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 3/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.2403 - accuracy: 0.2790 - categorical_accuracy: 0.2790 - precision: 0.5656 - recall: 0.0020 - val_loss: 2.2341 - val_accuracy: 0.2531 - val_categorical_accuracy: 0.2531 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 4/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 2.2176 - accuracy: 0.2758 - categorical_accuracy: 0.2758 - precision: 0.5752 - recall: 0.0018 - val_loss: 2.2132 - val_accuracy: 0.2609 - val_categorical_accuracy: 0.2609 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 5/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.1945 - accuracy: 0.2844 - categorical_accuracy: 0.2844 - precision: 0.5208 - recall: 0.0014 - val_loss: 2.1930 - val_accuracy: 0.2687 - val_categorical_accuracy: 0.2687 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 6/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.1738 - accuracy: 0.2904 - categorical_accuracy: 0.2904 - precision: 0.5377 - recall: 0.0016 - val_loss: 2.1742 - val_accuracy: 0.2734 - val_categorical_accuracy: 0.2734 - val_precision: 1.0000 - val_recall: 2.2075e-04 - lr: 1.0000e-04\n",
      "Epoch 7/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.1537 - accuracy: 0.2901 - categorical_accuracy: 0.2901 - precision: 0.3933 - recall: 9.9027e-04 - val_loss: 2.1574 - val_accuracy: 0.2765 - val_categorical_accuracy: 0.2765 - val_precision: 1.0000 - val_recall: 2.2075e-04 - lr: 1.0000e-04\n",
      "Epoch 8/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.1333 - accuracy: 0.2885 - categorical_accuracy: 0.2885 - precision: 0.3750 - recall: 6.7904e-04 - val_loss: 2.1426 - val_accuracy: 0.2702 - val_categorical_accuracy: 0.2702 - val_precision: 1.0000 - val_recall: 2.2075e-04 - lr: 1.0000e-04\n",
      "Epoch 9/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.1182 - accuracy: 0.2889 - categorical_accuracy: 0.2889 - precision: 0.2759 - recall: 6.7904e-04 - val_loss: 2.1281 - val_accuracy: 0.2850 - val_categorical_accuracy: 0.2850 - val_precision: 1.0000 - val_recall: 2.2075e-04 - lr: 1.0000e-04\n",
      "Epoch 10/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.1044 - accuracy: 0.2931 - categorical_accuracy: 0.2931 - precision: 0.3735 - recall: 8.7709e-04 - val_loss: 2.1146 - val_accuracy: 0.2835 - val_categorical_accuracy: 0.2835 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 11/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0902 - accuracy: 0.2937 - categorical_accuracy: 0.2937 - precision: 0.2791 - recall: 6.7904e-04 - val_loss: 2.1031 - val_accuracy: 0.2858 - val_categorical_accuracy: 0.2858 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 12/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0817 - accuracy: 0.2901 - categorical_accuracy: 0.2901 - precision: 0.2967 - recall: 7.6392e-04 - val_loss: 2.0923 - val_accuracy: 0.2812 - val_categorical_accuracy: 0.2812 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 13/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0690 - accuracy: 0.2907 - categorical_accuracy: 0.2907 - precision: 0.2286 - recall: 4.5269e-04 - val_loss: 2.0825 - val_accuracy: 0.2734 - val_categorical_accuracy: 0.2734 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 14/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0593 - accuracy: 0.2898 - categorical_accuracy: 0.2898 - precision: 0.3099 - recall: 6.2245e-04 - val_loss: 2.0728 - val_accuracy: 0.2718 - val_categorical_accuracy: 0.2718 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 15/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0516 - accuracy: 0.2915 - categorical_accuracy: 0.2915 - precision: 0.2118 - recall: 5.0928e-04 - val_loss: 2.0642 - val_accuracy: 0.2601 - val_categorical_accuracy: 0.2601 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 16/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0399 - accuracy: 0.2867 - categorical_accuracy: 0.2867 - precision: 0.2768 - recall: 8.7709e-04 - val_loss: 2.0565 - val_accuracy: 0.2625 - val_categorical_accuracy: 0.2625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 17/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0350 - accuracy: 0.2878 - categorical_accuracy: 0.2878 - precision: 0.3291 - recall: 7.3563e-04 - val_loss: 2.0498 - val_accuracy: 0.2601 - val_categorical_accuracy: 0.2601 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 18/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0289 - accuracy: 0.2841 - categorical_accuracy: 0.2841 - precision: 0.2778 - recall: 7.0733e-04 - val_loss: 2.0437 - val_accuracy: 0.2601 - val_categorical_accuracy: 0.2601 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 19/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0221 - accuracy: 0.2851 - categorical_accuracy: 0.2851 - precision: 0.2366 - recall: 6.2245e-04 - val_loss: 2.0385 - val_accuracy: 0.2625 - val_categorical_accuracy: 0.2625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 20/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0188 - accuracy: 0.2731 - categorical_accuracy: 0.2731 - precision: 0.3232 - recall: 9.0539e-04 - val_loss: 2.0336 - val_accuracy: 0.2578 - val_categorical_accuracy: 0.2578 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 21/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0165 - accuracy: 0.2769 - categorical_accuracy: 0.2769 - precision: 0.3187 - recall: 8.2051e-04 - val_loss: 2.0312 - val_accuracy: 0.2531 - val_categorical_accuracy: 0.2531 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 22/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0126 - accuracy: 0.2792 - categorical_accuracy: 0.2792 - precision: 0.2211 - recall: 5.9416e-04 - val_loss: 2.0279 - val_accuracy: 0.2539 - val_categorical_accuracy: 0.2539 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 23/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0079 - accuracy: 0.2744 - categorical_accuracy: 0.2744 - precision: 0.2208 - recall: 4.8099e-04 - val_loss: 2.0250 - val_accuracy: 0.2656 - val_categorical_accuracy: 0.2656 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 24/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0050 - accuracy: 0.2818 - categorical_accuracy: 0.2818 - precision: 0.2632 - recall: 5.6587e-04 - val_loss: 2.0224 - val_accuracy: 0.2671 - val_categorical_accuracy: 0.2671 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 25/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 2.0020 - accuracy: 0.2807 - categorical_accuracy: 0.2807 - precision: 0.2169 - recall: 5.0928e-04 - val_loss: 2.0197 - val_accuracy: 0.2601 - val_categorical_accuracy: 0.2601 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 26/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0002 - accuracy: 0.2784 - categorical_accuracy: 0.2784 - precision: 0.1333 - recall: 2.8293e-04 - val_loss: 2.0192 - val_accuracy: 0.2593 - val_categorical_accuracy: 0.2593 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 27/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 2.0011 - accuracy: 0.2792 - categorical_accuracy: 0.2792 - precision: 0.1500 - recall: 3.3952e-04 - val_loss: 2.0170 - val_accuracy: 0.2617 - val_categorical_accuracy: 0.2617 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 28/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9976 - accuracy: 0.2731 - categorical_accuracy: 0.2731 - precision: 0.2593 - recall: 5.9416e-04 - val_loss: 2.0152 - val_accuracy: 0.2570 - val_categorical_accuracy: 0.2570 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 29/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9969 - accuracy: 0.2685 - categorical_accuracy: 0.2685 - precision: 0.2151 - recall: 5.6587e-04 - val_loss: 2.0140 - val_accuracy: 0.2664 - val_categorical_accuracy: 0.2664 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 30/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9959 - accuracy: 0.2651 - categorical_accuracy: 0.2651 - precision: 0.1324 - recall: 2.5464e-04 - val_loss: 2.0123 - val_accuracy: 0.2383 - val_categorical_accuracy: 0.2383 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 31/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9936 - accuracy: 0.2677 - categorical_accuracy: 0.2677 - precision: 0.1867 - recall: 3.9611e-04 - val_loss: 2.0106 - val_accuracy: 0.2227 - val_categorical_accuracy: 0.2227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 32/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9919 - accuracy: 0.2659 - categorical_accuracy: 0.2659 - precision: 0.1918 - recall: 3.9611e-04 - val_loss: 2.0088 - val_accuracy: 0.2259 - val_categorical_accuracy: 0.2259 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 33/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9899 - accuracy: 0.2650 - categorical_accuracy: 0.2650 - precision: 0.2394 - recall: 4.8099e-04 - val_loss: 2.0077 - val_accuracy: 0.2305 - val_categorical_accuracy: 0.2305 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 34/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9902 - accuracy: 0.2608 - categorical_accuracy: 0.2608 - precision: 0.1045 - recall: 1.9805e-04 - val_loss: 2.0061 - val_accuracy: 0.2586 - val_categorical_accuracy: 0.2586 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 35/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9892 - accuracy: 0.2597 - categorical_accuracy: 0.2597 - precision: 0.1094 - recall: 1.9805e-04 - val_loss: 2.0050 - val_accuracy: 0.2212 - val_categorical_accuracy: 0.2212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 36/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9864 - accuracy: 0.2558 - categorical_accuracy: 0.2558 - precision: 0.1875 - recall: 3.3952e-04 - val_loss: 2.0032 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 37/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9848 - accuracy: 0.2589 - categorical_accuracy: 0.2589 - precision: 0.1373 - recall: 1.9805e-04 - val_loss: 2.0020 - val_accuracy: 0.2212 - val_categorical_accuracy: 0.2212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 38/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9831 - accuracy: 0.2529 - categorical_accuracy: 0.2529 - precision: 0.0933 - recall: 1.9805e-04 - val_loss: 2.0008 - val_accuracy: 0.2313 - val_categorical_accuracy: 0.2313 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 39/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9837 - accuracy: 0.2569 - categorical_accuracy: 0.2569 - precision: 0.1493 - recall: 2.8293e-04 - val_loss: 2.0004 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 40/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9801 - accuracy: 0.2615 - categorical_accuracy: 0.2615 - precision: 0.1905 - recall: 3.3952e-04 - val_loss: 1.9986 - val_accuracy: 0.2227 - val_categorical_accuracy: 0.2227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 41/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9805 - accuracy: 0.2617 - categorical_accuracy: 0.2617 - precision: 0.2381 - recall: 4.2440e-04 - val_loss: 1.9979 - val_accuracy: 0.2290 - val_categorical_accuracy: 0.2290 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 42/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9785 - accuracy: 0.2588 - categorical_accuracy: 0.2588 - precision: 0.1724 - recall: 2.8293e-04 - val_loss: 1.9971 - val_accuracy: 0.2274 - val_categorical_accuracy: 0.2274 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 43/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9803 - accuracy: 0.2582 - categorical_accuracy: 0.2582 - precision: 0.1379 - recall: 2.2635e-04 - val_loss: 1.9960 - val_accuracy: 0.2142 - val_categorical_accuracy: 0.2142 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 44/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9779 - accuracy: 0.2458 - categorical_accuracy: 0.2458 - precision: 0.2000 - recall: 2.5464e-04 - val_loss: 1.9953 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 45/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9763 - accuracy: 0.2499 - categorical_accuracy: 0.2499 - precision: 0.1017 - recall: 1.6976e-04 - val_loss: 1.9941 - val_accuracy: 0.2134 - val_categorical_accuracy: 0.2134 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 46/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9779 - accuracy: 0.2512 - categorical_accuracy: 0.2512 - precision: 0.1509 - recall: 2.2635e-04 - val_loss: 1.9943 - val_accuracy: 0.2142 - val_categorical_accuracy: 0.2142 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 47/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9762 - accuracy: 0.2467 - categorical_accuracy: 0.2467 - precision: 0.0682 - recall: 8.4880e-05 - val_loss: 1.9930 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 48/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9750 - accuracy: 0.2448 - categorical_accuracy: 0.2448 - precision: 0.1765 - recall: 2.5464e-04 - val_loss: 1.9929 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 49/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9746 - accuracy: 0.2474 - categorical_accuracy: 0.2474 - precision: 0.0877 - recall: 1.4147e-04 - val_loss: 1.9923 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 50/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9747 - accuracy: 0.2470 - categorical_accuracy: 0.2470 - precision: 0.0833 - recall: 1.4147e-04 - val_loss: 1.9910 - val_accuracy: 0.2266 - val_categorical_accuracy: 0.2266 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 51/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9739 - accuracy: 0.2542 - categorical_accuracy: 0.2542 - precision: 0.1875 - recall: 2.5464e-04 - val_loss: 1.9904 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 52/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9714 - accuracy: 0.2562 - categorical_accuracy: 0.2562 - precision: 0.1538 - recall: 2.2635e-04 - val_loss: 1.9892 - val_accuracy: 0.2251 - val_categorical_accuracy: 0.2251 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 53/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9707 - accuracy: 0.2469 - categorical_accuracy: 0.2469 - precision: 0.0333 - recall: 5.6587e-05 - val_loss: 1.9890 - val_accuracy: 0.2282 - val_categorical_accuracy: 0.2282 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 54/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9703 - accuracy: 0.2558 - categorical_accuracy: 0.2558 - precision: 0.0962 - recall: 1.4147e-04 - val_loss: 1.9883 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 55/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9715 - accuracy: 0.2468 - categorical_accuracy: 0.2468 - precision: 0.0577 - recall: 8.4880e-05 - val_loss: 1.9875 - val_accuracy: 0.2196 - val_categorical_accuracy: 0.2196 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 56/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9693 - accuracy: 0.2476 - categorical_accuracy: 0.2476 - precision: 0.1333 - recall: 1.6976e-04 - val_loss: 1.9871 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 57/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9698 - accuracy: 0.2450 - categorical_accuracy: 0.2450 - precision: 0.0833 - recall: 1.1317e-04 - val_loss: 1.9874 - val_accuracy: 0.2282 - val_categorical_accuracy: 0.2282 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 58/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9686 - accuracy: 0.2421 - categorical_accuracy: 0.2421 - precision: 0.0732 - recall: 8.4880e-05 - val_loss: 1.9866 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 59/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9682 - accuracy: 0.2409 - categorical_accuracy: 0.2409 - precision: 0.0303 - recall: 2.8293e-05 - val_loss: 1.9865 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 60/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9673 - accuracy: 0.2399 - categorical_accuracy: 0.2399 - precision: 0.0222 - recall: 2.8293e-05 - val_loss: 1.9851 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 61/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9667 - accuracy: 0.2337 - categorical_accuracy: 0.2337 - precision: 0.1351 - recall: 1.4147e-04 - val_loss: 1.9845 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 62/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9654 - accuracy: 0.2369 - categorical_accuracy: 0.2369 - precision: 0.0312 - recall: 2.8293e-05 - val_loss: 1.9838 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 63/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9661 - accuracy: 0.2383 - categorical_accuracy: 0.2383 - precision: 0.1515 - recall: 1.4147e-04 - val_loss: 1.9842 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 64/150\n",
      "321/321 [==============================] - 1s 3ms/step - loss: 1.9663 - accuracy: 0.2352 - categorical_accuracy: 0.2352 - precision: 0.0571 - recall: 5.6587e-05 - val_loss: 1.9841 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 65/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9650 - accuracy: 0.2373 - categorical_accuracy: 0.2373 - precision: 0.1081 - recall: 1.1317e-04 - val_loss: 1.9836 - val_accuracy: 0.2259 - val_categorical_accuracy: 0.2259 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 66/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9645 - accuracy: 0.2440 - categorical_accuracy: 0.2440 - precision: 0.0769 - recall: 5.6587e-05 - val_loss: 1.9830 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 67/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9645 - accuracy: 0.2451 - categorical_accuracy: 0.2451 - precision: 0.0909 - recall: 8.4880e-05 - val_loss: 1.9827 - val_accuracy: 0.2243 - val_categorical_accuracy: 0.2243 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 68/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9648 - accuracy: 0.2423 - categorical_accuracy: 0.2423 - precision: 0.0526 - recall: 5.6587e-05 - val_loss: 1.9828 - val_accuracy: 0.2227 - val_categorical_accuracy: 0.2227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 69/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9658 - accuracy: 0.2330 - categorical_accuracy: 0.2330 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9825 - val_accuracy: 0.2336 - val_categorical_accuracy: 0.2336 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 70/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9639 - accuracy: 0.2408 - categorical_accuracy: 0.2408 - precision: 0.0588 - recall: 5.6587e-05 - val_loss: 1.9828 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 71/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9647 - accuracy: 0.2353 - categorical_accuracy: 0.2353 - precision: 0.1026 - recall: 1.1317e-04 - val_loss: 1.9821 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 72/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9645 - accuracy: 0.2414 - categorical_accuracy: 0.2414 - precision: 0.0625 - recall: 5.6587e-05 - val_loss: 1.9822 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 73/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9651 - accuracy: 0.2296 - categorical_accuracy: 0.2296 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9828 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 74/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9644 - accuracy: 0.2343 - categorical_accuracy: 0.2343 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9820 - val_accuracy: 0.2336 - val_categorical_accuracy: 0.2336 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 75/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9640 - accuracy: 0.2364 - categorical_accuracy: 0.2364 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9817 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 76/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9630 - accuracy: 0.2357 - categorical_accuracy: 0.2357 - precision: 0.0667 - recall: 2.8293e-05 - val_loss: 1.9814 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 77/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9635 - accuracy: 0.2330 - categorical_accuracy: 0.2330 - precision: 0.1333 - recall: 5.6587e-05 - val_loss: 1.9811 - val_accuracy: 0.2204 - val_categorical_accuracy: 0.2204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 78/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9626 - accuracy: 0.2391 - categorical_accuracy: 0.2391 - precision: 0.2105 - recall: 1.1317e-04 - val_loss: 1.9809 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 79/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9632 - accuracy: 0.2326 - categorical_accuracy: 0.2326 - precision: 0.0833 - recall: 5.6587e-05 - val_loss: 1.9807 - val_accuracy: 0.2212 - val_categorical_accuracy: 0.2212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 80/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9633 - accuracy: 0.2340 - categorical_accuracy: 0.2340 - precision: 0.1667 - recall: 1.1317e-04 - val_loss: 1.9810 - val_accuracy: 0.2150 - val_categorical_accuracy: 0.2150 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 81/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9621 - accuracy: 0.2353 - categorical_accuracy: 0.2353 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9811 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 82/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9619 - accuracy: 0.2398 - categorical_accuracy: 0.2398 - precision: 0.1500 - recall: 8.4880e-05 - val_loss: 1.9808 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.0000e-04\n",
      "Epoch 83/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9632 - accuracy: 0.2319 - categorical_accuracy: 0.2319 - precision: 0.0500 - recall: 2.8293e-05 - val_loss: 1.9807 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 84/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9624 - accuracy: 0.2337 - categorical_accuracy: 0.2337 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9802 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 85/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9618 - accuracy: 0.2396 - categorical_accuracy: 0.2396 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9800 - val_accuracy: 0.2227 - val_categorical_accuracy: 0.2227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 86/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9611 - accuracy: 0.2328 - categorical_accuracy: 0.2328 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9798 - val_accuracy: 0.2227 - val_categorical_accuracy: 0.2227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 87/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9604 - accuracy: 0.2368 - categorical_accuracy: 0.2368 - precision: 0.0625 - recall: 2.8293e-05 - val_loss: 1.9796 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 88/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9607 - accuracy: 0.2315 - categorical_accuracy: 0.2315 - precision: 0.1111 - recall: 2.8293e-05 - val_loss: 1.9793 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 89/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9600 - accuracy: 0.2357 - categorical_accuracy: 0.2357 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9790 - val_accuracy: 0.2220 - val_categorical_accuracy: 0.2220 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 90/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9592 - accuracy: 0.2359 - categorical_accuracy: 0.2359 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9787 - val_accuracy: 0.2220 - val_categorical_accuracy: 0.2220 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 91/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9592 - accuracy: 0.2326 - categorical_accuracy: 0.2326 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9784 - val_accuracy: 0.2204 - val_categorical_accuracy: 0.2204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 92/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9598 - accuracy: 0.2358 - categorical_accuracy: 0.2358 - precision: 0.1538 - recall: 5.6587e-05 - val_loss: 1.9780 - val_accuracy: 0.2204 - val_categorical_accuracy: 0.2204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 93/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9590 - accuracy: 0.2385 - categorical_accuracy: 0.2385 - precision: 0.0714 - recall: 2.8293e-05 - val_loss: 1.9782 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 94/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9580 - accuracy: 0.2318 - categorical_accuracy: 0.2318 - precision: 0.0714 - recall: 2.8293e-05 - val_loss: 1.9775 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 95/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9583 - accuracy: 0.2360 - categorical_accuracy: 0.2360 - precision: 0.1250 - recall: 5.6587e-05 - val_loss: 1.9774 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 96/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9580 - accuracy: 0.2295 - categorical_accuracy: 0.2295 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9772 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 97/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9572 - accuracy: 0.2263 - categorical_accuracy: 0.2263 - precision: 0.2000 - recall: 5.6587e-05 - val_loss: 1.9768 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 98/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9572 - accuracy: 0.2435 - categorical_accuracy: 0.2435 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9764 - val_accuracy: 0.2181 - val_categorical_accuracy: 0.2181 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 99/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9570 - accuracy: 0.2361 - categorical_accuracy: 0.2361 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9762 - val_accuracy: 0.2220 - val_categorical_accuracy: 0.2220 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 100/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9569 - accuracy: 0.2282 - categorical_accuracy: 0.2282 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9760 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 101/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9566 - accuracy: 0.2277 - categorical_accuracy: 0.2277 - precision: 0.0833 - recall: 2.8293e-05 - val_loss: 1.9758 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 102/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9562 - accuracy: 0.2280 - categorical_accuracy: 0.2280 - precision: 0.1000 - recall: 2.8293e-05 - val_loss: 1.9753 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 103/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9555 - accuracy: 0.2309 - categorical_accuracy: 0.2309 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9751 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 104/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9558 - accuracy: 0.2280 - categorical_accuracy: 0.2280 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9748 - val_accuracy: 0.2204 - val_categorical_accuracy: 0.2204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 105/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9548 - accuracy: 0.2305 - categorical_accuracy: 0.2305 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9745 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 106/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9542 - accuracy: 0.2301 - categorical_accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9743 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 107/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9547 - accuracy: 0.2290 - categorical_accuracy: 0.2290 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9742 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 108/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9544 - accuracy: 0.2251 - categorical_accuracy: 0.2251 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9738 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 109/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9543 - accuracy: 0.2291 - categorical_accuracy: 0.2291 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9734 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 110/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9530 - accuracy: 0.2258 - categorical_accuracy: 0.2258 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9730 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 111/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9531 - accuracy: 0.2329 - categorical_accuracy: 0.2329 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9727 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 112/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9530 - accuracy: 0.2329 - categorical_accuracy: 0.2329 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9726 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 113/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9532 - accuracy: 0.2277 - categorical_accuracy: 0.2277 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9723 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 114/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9521 - accuracy: 0.2300 - categorical_accuracy: 0.2300 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9718 - val_accuracy: 0.2212 - val_categorical_accuracy: 0.2212 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 115/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9524 - accuracy: 0.2306 - categorical_accuracy: 0.2306 - precision: 0.1000 - recall: 2.8293e-05 - val_loss: 1.9717 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 116/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9523 - accuracy: 0.2305 - categorical_accuracy: 0.2305 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9713 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 117/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9517 - accuracy: 0.2330 - categorical_accuracy: 0.2330 - precision: 0.0769 - recall: 2.8293e-05 - val_loss: 1.9712 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 118/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9511 - accuracy: 0.2301 - categorical_accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9711 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 119/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9514 - accuracy: 0.2282 - categorical_accuracy: 0.2282 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9706 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 120/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9509 - accuracy: 0.2260 - categorical_accuracy: 0.2260 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9703 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 121/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9513 - accuracy: 0.2327 - categorical_accuracy: 0.2327 - precision: 0.0909 - recall: 2.8293e-05 - val_loss: 1.9699 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 122/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9504 - accuracy: 0.2350 - categorical_accuracy: 0.2350 - precision: 0.1000 - recall: 2.8293e-05 - val_loss: 1.9697 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 123/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9500 - accuracy: 0.2264 - categorical_accuracy: 0.2264 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9696 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 124/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9498 - accuracy: 0.2232 - categorical_accuracy: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9692 - val_accuracy: 0.2181 - val_categorical_accuracy: 0.2181 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 125/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9491 - accuracy: 0.2338 - categorical_accuracy: 0.2338 - precision: 0.2000 - recall: 2.8293e-05 - val_loss: 1.9690 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 126/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9476 - accuracy: 0.2377 - categorical_accuracy: 0.2377 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9686 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 127/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9481 - accuracy: 0.2262 - categorical_accuracy: 0.2262 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9683 - val_accuracy: 0.2196 - val_categorical_accuracy: 0.2196 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 128/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9488 - accuracy: 0.2299 - categorical_accuracy: 0.2299 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9682 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 129/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9484 - accuracy: 0.2244 - categorical_accuracy: 0.2244 - precision: 0.1111 - recall: 2.8293e-05 - val_loss: 1.9679 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 130/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9481 - accuracy: 0.2323 - categorical_accuracy: 0.2323 - precision: 0.1250 - recall: 2.8293e-05 - val_loss: 1.9675 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 131/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9465 - accuracy: 0.2237 - categorical_accuracy: 0.2237 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9672 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 132/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9479 - accuracy: 0.2312 - categorical_accuracy: 0.2312 - precision: 0.0714 - recall: 2.8293e-05 - val_loss: 1.9668 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 133/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9477 - accuracy: 0.2287 - categorical_accuracy: 0.2287 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9665 - val_accuracy: 0.2227 - val_categorical_accuracy: 0.2227 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 134/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9466 - accuracy: 0.2264 - categorical_accuracy: 0.2264 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9662 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 135/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9460 - accuracy: 0.2341 - categorical_accuracy: 0.2341 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9660 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 136/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9462 - accuracy: 0.2300 - categorical_accuracy: 0.2300 - precision: 0.1000 - recall: 2.8293e-05 - val_loss: 1.9658 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 137/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9463 - accuracy: 0.2323 - categorical_accuracy: 0.2323 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9655 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 138/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9454 - accuracy: 0.2301 - categorical_accuracy: 0.2301 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9653 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 139/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9459 - accuracy: 0.2301 - categorical_accuracy: 0.2301 - precision: 0.1538 - recall: 5.6587e-05 - val_loss: 1.9651 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 140/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9450 - accuracy: 0.2268 - categorical_accuracy: 0.2268 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9646 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 141/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9443 - accuracy: 0.2276 - categorical_accuracy: 0.2276 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9643 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 142/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9449 - accuracy: 0.2289 - categorical_accuracy: 0.2289 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9640 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 143/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9437 - accuracy: 0.2352 - categorical_accuracy: 0.2352 - precision: 0.0769 - recall: 2.8293e-05 - val_loss: 1.9637 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 144/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9436 - accuracy: 0.2269 - categorical_accuracy: 0.2269 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9637 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 145/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9434 - accuracy: 0.2311 - categorical_accuracy: 0.2311 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9631 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 146/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9431 - accuracy: 0.2298 - categorical_accuracy: 0.2298 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9629 - val_accuracy: 0.2173 - val_categorical_accuracy: 0.2173 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 147/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9441 - accuracy: 0.2333 - categorical_accuracy: 0.2333 - precision: 0.2857 - recall: 5.6587e-05 - val_loss: 1.9625 - val_accuracy: 0.2204 - val_categorical_accuracy: 0.2204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 148/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9427 - accuracy: 0.2354 - categorical_accuracy: 0.2354 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9622 - val_accuracy: 0.2188 - val_categorical_accuracy: 0.2188 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 149/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9426 - accuracy: 0.2275 - categorical_accuracy: 0.2275 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9621 - val_accuracy: 0.2157 - val_categorical_accuracy: 0.2157 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n",
      "Epoch 150/150\n",
      "321/321 [==============================] - 1s 4ms/step - loss: 1.9423 - accuracy: 0.2265 - categorical_accuracy: 0.2265 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9616 - val_accuracy: 0.2165 - val_categorical_accuracy: 0.2165 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir models/logs/fit\n",
    "\n",
    "# Train the model using ModelHelper's train_model method\n",
    "history = model_helper.train_model(\n",
    "    model=model,\n",
    "    train_data=train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 1ms/step - loss: 2.2844 - accuracy: 0.2814 - categorical_accuracy: 0.2814 - precision: 1.0000 - recall: 2.1993e-04\n",
      "[2.284449577331543, 0.2813717722892761, 0.2813717722892761, 1.0, 0.00021992521942593157]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = model.evaluate(test_dataset)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Error saving model: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<tf_keras.src.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x00000210C9A95460>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model_helper.save_model(model, \"text_classification_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Use Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: Save or restore weights that is not an instance of `tf.Variable` is not supported in h5, use `save_format='tf'` instead. Received a model or layer TextVectorization with weights [<tf_keras.src.layers.preprocessing.index_lookup.VocabWeightHandler object at 0x0000021085AE2EA0>]\n",
      "[[ 7.80787924e-03 -1.44528849e-02  6.46416424e-03 -2.56793685e-02\n",
      "  -9.65327397e-02  8.58551189e-02  6.98082447e-02  3.99074377e-03\n",
      "  -8.74180868e-02  2.87988503e-02  2.87528969e-02  1.01409713e-02\n",
      "   2.93969605e-02 -8.59811381e-02 -3.12866308e-02  7.26936832e-02\n",
      "   4.58125258e-03  8.62116888e-02  2.10175058e-03  1.01940013e-01\n",
      "   7.18423799e-02  4.75919712e-03 -9.46561049e-05  5.05877845e-02\n",
      "   1.56101644e-01  4.36919257e-02 -1.51563315e-02  2.40388163e-03\n",
      "  -1.58895310e-02 -2.51775812e-02 -1.06737919e-01  7.07412809e-02\n",
      "   4.94894832e-02  3.08563840e-02  2.91129984e-02 -3.40982117e-02\n",
      "   1.11657195e-01  4.70892824e-02 -6.71625230e-03  2.94581391e-02\n",
      "  -4.25266698e-02 -3.54633946e-03 -1.84288230e-02 -1.99071560e-02\n",
      "  -8.40682983e-02 -8.74066129e-02  5.21774963e-02 -1.68546159e-02\n",
      "   4.58840802e-02  2.17433758e-02 -6.76908568e-02  4.28052358e-02\n",
      "  -4.56975177e-02 -2.15390436e-02  2.67212316e-02 -1.36472238e-02\n",
      "   5.95129468e-03  8.63851160e-02  2.10052487e-02 -1.97168756e-02\n",
      "   1.13614928e-02 -7.40882158e-02 -4.86826850e-03 -4.10203375e-02\n",
      "   4.74912263e-02  1.97790246e-02 -2.54844539e-02 -2.54539941e-02\n",
      "  -1.00875743e-01 -3.24559696e-02  7.74060190e-02  3.55644152e-02\n",
      "   3.60606425e-02 -4.41351347e-02 -4.15929146e-02 -2.54299771e-02\n",
      "   2.59144269e-02  9.97828841e-02  2.47023851e-02 -5.32053038e-02\n",
      "  -3.03913392e-02 -6.45044297e-02 -3.00089829e-02  3.04775108e-02\n",
      "   2.26590876e-02  3.11912540e-02 -3.30706500e-02 -8.55620485e-03\n",
      "   9.77698416e-02  5.59805986e-03 -3.21980603e-02 -3.08516230e-02\n",
      "   5.29674031e-02 -8.34014936e-05 -1.36827692e-01 -5.64701855e-04\n",
      "  -2.26151366e-02 -5.05981185e-02  7.29595125e-02  8.11563283e-02\n",
      "  -4.45732698e-02  7.35438541e-02  7.91888833e-02 -8.04399513e-03\n",
      "   5.64965270e-02 -1.33524416e-02  8.16367418e-02  3.63839678e-02\n",
      "  -2.52702944e-02 -4.30326862e-03  6.32501468e-02 -1.81358233e-02\n",
      "  -4.86677736e-02  2.52714921e-02  1.24649378e-02 -7.28349909e-02\n",
      "   5.06964438e-02 -4.06837910e-02 -5.03948852e-02 -4.21512686e-02\n",
      "  -2.28825840e-03 -4.10881154e-02 -8.70722085e-02 -2.78281271e-02\n",
      "  -8.98407027e-03  2.32613813e-02 -3.11367121e-02  8.48703468e-33\n",
      "  -8.69430136e-03 -1.00875925e-02  1.03917502e-01  8.03878531e-02\n",
      "  -1.09626139e-02  6.99294731e-02 -4.84222779e-03  3.21942158e-02\n",
      "   1.75167508e-02 -4.37184311e-02  2.85164686e-03  2.49363557e-02\n",
      "   1.45712513e-02 -3.53305675e-02  4.30735983e-02 -4.75503914e-02\n",
      "  -1.21541053e-01 -6.06756890e-03  3.28565128e-02  3.72109003e-02\n",
      "   3.75833102e-02  2.96558533e-02  2.65982235e-03 -6.02332614e-02\n",
      "  -5.89765199e-02 -4.31454964e-02  7.11720288e-02 -8.55362322e-03\n",
      "  -3.01106200e-02  4.97582629e-02  7.27541223e-02  8.29466339e-03\n",
      "   9.00040939e-02 -4.94955182e-02  8.43963679e-03  9.10962094e-03\n",
      "   2.64840871e-02 -3.22102085e-02 -5.68740349e-03 -2.53543872e-02\n",
      "  -3.66960168e-02 -6.19153865e-02 -6.33224705e-03  7.89630711e-02\n",
      "  -9.05002281e-02 -2.35932972e-02  6.15361929e-02  6.21905457e-03\n",
      "   7.59215727e-02  4.80186492e-02 -5.01365885e-02  4.01865393e-02\n",
      "  -6.12934902e-02 -3.53846736e-02 -5.31219654e-02 -2.22593453e-02\n",
      "  -1.19259744e-03  1.80792958e-02 -2.82183266e-03  4.22932133e-02\n",
      "   5.33000566e-02  1.44053586e-02  4.99451458e-02 -7.67344143e-03\n",
      "  -7.88567290e-02  2.75330152e-02 -2.45353160e-03 -3.71607090e-03\n",
      "   2.00694837e-02  4.64915857e-02  2.97161322e-02 -3.81348990e-02\n",
      "   3.62603343e-03  1.02467306e-01 -3.38630565e-02  1.05056576e-01\n",
      "   1.56934336e-02 -2.78142281e-02 -5.53614348e-02 -4.65550795e-02\n",
      "   3.94237414e-02 -6.87384307e-02  3.22860442e-02  1.29611436e-02\n",
      "   1.15911201e-01  5.07804714e-02  3.55973281e-02 -1.00378931e-01\n",
      "  -2.52621318e-03 -2.74653174e-02  6.18899874e-02 -1.49929132e-02\n",
      "   8.32444429e-02 -1.00433432e-01 -1.03428364e-01 -7.92628567e-33\n",
      "  -9.25232023e-02  1.24962702e-02  4.81627602e-03 -5.96378371e-02\n",
      "   2.04673130e-02 -5.11252135e-02 -3.43741791e-04 -1.37166843e-01\n",
      "  -4.27424535e-02  3.84765561e-04 -1.61481351e-02 -5.31370491e-02\n",
      "   2.19196305e-02  1.98029224e-02  3.09379678e-02 -2.81003700e-03\n",
      "   8.64957646e-02 -6.46618381e-02 -5.46987839e-02 -9.35491920e-02\n",
      "  -4.46290895e-02  6.14789985e-02 -3.29558067e-02  1.39616445e-01\n",
      "  -1.00271434e-01  4.38610464e-02 -3.61036249e-02  2.04758607e-02\n",
      "   1.65209118e-02  1.86032206e-02 -1.80727127e-03 -6.87238052e-02\n",
      "  -1.63898654e-02  2.13362500e-02 -9.16789472e-02 -3.75746228e-02\n",
      "  -3.14064845e-02 -1.03159659e-01  5.66423908e-02 -7.03755245e-02\n",
      "  -8.13019369e-03 -9.60855260e-02 -1.16996840e-02  9.56855714e-03\n",
      "  -1.98917650e-02 -2.14092713e-02 -7.08636642e-02  8.46200343e-03\n",
      "   8.36855173e-03 -2.76264157e-02  3.19928639e-02  1.02515601e-01\n",
      "  -7.14282691e-02  9.92311612e-02 -5.03786234e-03  3.38161774e-02\n",
      "   4.24031243e-02 -7.34072924e-03  5.15478626e-02  6.04495890e-02\n",
      "  -8.16773474e-02  1.88765302e-02  1.89337153e-02  3.69185619e-02\n",
      "   3.22232768e-02 -6.15826435e-02 -5.19962702e-03 -1.26098067e-01\n",
      "  -2.40174066e-02 -2.89024990e-02 -5.81593020e-03  4.03790027e-02\n",
      "  -5.34722246e-02  4.60682400e-02 -8.89129341e-02  8.24407637e-02\n",
      "  -4.24355865e-02  4.70482046e-03 -2.38838345e-02 -1.53547274e-02\n",
      "   3.30894254e-02 -4.57459986e-02  1.70112234e-02 -1.19330473e-02\n",
      "  -6.60377219e-02 -1.77703593e-02  6.61385804e-02 -7.67567456e-02\n",
      "  -2.86203045e-02 -6.04644069e-04 -1.81209724e-02  1.66583643e-03\n",
      "   1.09622367e-02  1.51795074e-02  2.28642850e-04 -3.71085704e-08\n",
      "  -8.31353758e-03  1.25022460e-04 -3.03429794e-02  3.35219838e-02\n",
      "   2.27205567e-02 -7.73107726e-03 -5.43748587e-02  9.38131288e-02\n",
      "  -7.66236382e-03 -2.23431736e-03  2.29963828e-02  1.70469265e-02\n",
      "   1.98515337e-02  7.60079771e-02  9.42344964e-03 -1.84741169e-02\n",
      "   1.53545421e-02 -4.04079668e-02 -7.06517994e-02 -1.04121948e-02\n",
      "  -3.86155806e-02 -1.02596562e-02 -6.82087988e-03  5.96759208e-02\n",
      "   2.55043991e-02  2.85396762e-02 -1.65744610e-02  1.79695755e-01\n",
      "   7.88444504e-02 -4.65118624e-02  1.28747069e-03  1.71071123e-02\n",
      "  -6.08967841e-02  2.65735039e-03 -6.12265877e-02  2.37627029e-02\n",
      "  -9.90877859e-04  1.52336694e-02 -4.84543331e-02  2.00082269e-02\n",
      "   2.95267347e-02  3.06237210e-03 -6.40541986e-02  9.03525949e-02\n",
      "  -1.31257325e-02 -1.23560596e-02 -3.45345922e-02 -2.76839845e-02\n",
      "   7.02800229e-03 -1.00114100e-01  2.35807002e-02  3.11898477e-02\n",
      "   4.04712968e-02 -1.01443669e-02  1.20102474e-02 -4.17667031e-02\n",
      "  -9.32373628e-02 -1.76480657e-03 -1.47410901e-02  1.11326352e-01\n",
      "   3.44987889e-03 -1.91769619e-02  1.15963379e-02 -2.95077506e-02]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m test_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBarbara Buono by the numbers: As a Trenton politician, she voted to raise taxes 154 times. Under her, property taxes up 70 percent. Backed a 16 percent sales tax increase. Utilities, nursing homes, cell phones, parking lots, lottery wins, gyms She taxed them all. Architect of Corzines budget, she drove New Jersey $2 billion into debt. Barbara Buono by the numbers: taking New Jersey backwards.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_helper\u001b[38;5;241m.\u001b[39mpreprocess_text(test_string))\n\u001b[1;32m----> 5\u001b[0m prediction \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(model_helper\u001b[38;5;241m.\u001b[39mpreprocess_text(test_string))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = model_helper.load_model(\"text_classification_model\")\n",
    "test_string = 'Barbara Buono by the numbers: As a Trenton politician, she voted to raise taxes 154 times. Under her, property taxes up 70 percent. Backed a 16 percent sales tax increase. Utilities, nursing homes, cell phones, parking lots, lottery wins, gyms She taxed them all. Architect of Corzines budget, she drove New Jersey $2 billion into debt. Barbara Buono by the numbers: taking New Jersey backwards.'\n",
    "print(model_helper.preprocess_text(test_string))\n",
    "prediction = loaded_model.predict(model_helper.preprocess_text(test_string))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use prepared test data to get Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 60), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))>\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step\n",
      "\n",
      "Sample predictions:\n",
      "Example 1:\n",
      "Predicted probabilities: [0.22542152 0.07708871 0.25169054 0.25748774 0.18831144]\n",
      "Predicted class: 3\n",
      "Actual class: 3\n",
      "\n",
      "Example 2:\n",
      "Predicted probabilities: [0.20950253 0.07118634 0.2756604  0.26801345 0.17563727]\n",
      "Predicted class: 2\n",
      "Actual class: 0\n",
      "\n",
      "Example 3:\n",
      "Predicted probabilities: [0.23635894 0.09474026 0.2315793  0.23723659 0.20008487]\n",
      "Predicted class: 3\n",
      "Actual class: 4\n",
      "\n",
      "Example 4:\n",
      "Predicted probabilities: [0.23215993 0.08755633 0.23721452 0.24035522 0.202714  ]\n",
      "Predicted class: 3\n",
      "Actual class: 3\n",
      "\n",
      "Example 5:\n",
      "Predicted probabilities: [0.21936993 0.06663408 0.2585142  0.26102304 0.1944587 ]\n",
      "Predicted class: 3\n",
      "Actual class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "print(test_dataset)\n",
    "predictions = loaded_model.predict(test_dataset)\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Predicted probabilities: {predictions[i]}\")\n",
    "    print(f\"Predicted class: {predicted_classes[i]}\")\n",
    "    print(f\"Actual class: {np.argmax(test_labels[i])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_classification_model']\n"
     ]
    }
   ],
   "source": [
    "models_list = model_helper.list_models()\n",
    "print(models_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
