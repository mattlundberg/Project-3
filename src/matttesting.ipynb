{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from main import DataImporter\n",
    "from models.modelhelper import ModelHelper\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_importer = DataImporter()\n",
    "data_importer.import_data()\n",
    "\n",
    "ds_train = data_importer.get_train_data()\n",
    "ds_test = data_importer.get_test_data()\n",
    "ds_validation = data_importer.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10269 entries, 0 to 10268\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    10269 non-null  object \n",
      " 1   label                 10269 non-null  int64  \n",
      " 2   statement             10269 non-null  object \n",
      " 3   subject               10269 non-null  object \n",
      " 4   speaker               10269 non-null  object \n",
      " 5   job_title             10269 non-null  object \n",
      " 6   state_info            10269 non-null  object \n",
      " 7   party_affiliation     10269 non-null  object \n",
      " 8   barely_true_counts    10269 non-null  float32\n",
      " 9   false_counts          10269 non-null  float32\n",
      " 10  half_true_counts      10269 non-null  float32\n",
      " 11  mostly_true_counts    10269 non-null  float32\n",
      " 12  pants_on_fire_counts  10269 non-null  float32\n",
      " 13  context               10269 non-null  object \n",
      "dtypes: float32(5), int64(1), object(8)\n",
      "memory usage: 922.7+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1283 entries, 0 to 1282\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1283 non-null   object \n",
      " 1   label                 1283 non-null   int64  \n",
      " 2   statement             1283 non-null   object \n",
      " 3   subject               1283 non-null   object \n",
      " 4   speaker               1283 non-null   object \n",
      " 5   job_title             1283 non-null   object \n",
      " 6   state_info            1283 non-null   object \n",
      " 7   party_affiliation     1283 non-null   object \n",
      " 8   barely_true_counts    1283 non-null   float32\n",
      " 9   false_counts          1283 non-null   float32\n",
      " 10  half_true_counts      1283 non-null   float32\n",
      " 11  mostly_true_counts    1283 non-null   float32\n",
      " 12  pants_on_fire_counts  1283 non-null   float32\n",
      " 13  context               1283 non-null   object \n",
      "dtypes: float32(5), int64(1), object(8)\n",
      "memory usage: 115.4+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1284 entries, 0 to 1283\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   id                    1284 non-null   object \n",
      " 1   label                 1284 non-null   int64  \n",
      " 2   statement             1284 non-null   object \n",
      " 3   subject               1284 non-null   object \n",
      " 4   speaker               1284 non-null   object \n",
      " 5   job_title             1284 non-null   object \n",
      " 6   state_info            1284 non-null   object \n",
      " 7   party_affiliation     1284 non-null   object \n",
      " 8   barely_true_counts    1284 non-null   float32\n",
      " 9   false_counts          1284 non-null   float32\n",
      " 10  half_true_counts      1284 non-null   float32\n",
      " 11  mostly_true_counts    1284 non-null   float32\n",
      " 12  pants_on_fire_counts  1284 non-null   float32\n",
      " 13  context               1284 non-null   object \n",
      "dtypes: float32(5), int64(1), object(8)\n",
      "memory usage: 115.5+ KB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds_train.info()\n",
    "print('\\n')\n",
    "ds_test.info()\n",
    "print('\\n')\n",
    "ds_validation.info()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>\"I'm the only person on this stage who has wor...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>However, it took $19.5 million in Oregon Lotte...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Says GOP primary opponents Glenn Grothman and ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>For the first time in history, the share of th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Since 2000, nearly 12 million Americans have s...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>When Mitt Romney was governor of Massachusetts...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>The economy bled $24 billion due to the govern...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>Most of the (Affordable Care Act) has already ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>In this last election in November, ... 63 perc...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>\"McCain opposed a requirement that the governm...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Water rates in Manila, Philippines, were raise...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>Almost 100,000 people left Puerto Rico last year.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Women and men both are making less when you ad...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>The United States has the highest corporate ta...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>We just had the best year for the auto industr...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>Says Scott Walker favors cutting up to 350,000...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>Says Mitt Romney wants to get rid of Planned P...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>I dont know who (Jonathan Gruber) is.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>Hate crimes against American Muslims and mosqu...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Rick Perry has never lost an election and rema...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>ISIS supporter tweeted at 10:34 a.m. Shooting ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>Youth unemployment in minority communities is ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>Says Paul Ryan is still endorsing Trump.</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>If you look at states that are right to work, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>What (the Obama administration is) going to co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>We cut business taxes so today 70 percent of o...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>Says Mark Pryor votes with Obama 93 percent of...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>We have a federal government that thinks they ...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>Austin is a city that has basically doubled in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>The nuclear test conducted in our nation this ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>In the case of a catastrophic event, the Atlan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>Under President George W. Bush, we added $4.9 ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>Says a U.S. Supreme Court justice suggested th...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Says Marco Rubio skipped 18 defense votes incl...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>Rep. David Cicilline is responsible for the fe...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>Says Ohio budget item later signed into law by...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>\"We have a director of homeland security who c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>African-American youth unemployment is 51 perc...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>Obamacare will provide insurance to all non-U....</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>President Barack Obama took exactly none of hi...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>It was under Barack Obama and Hillary Clinton ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>Hillary Clinton in 2005 co-sponsored legislati...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          statement  \\\n",
       "0       0  Says the Annies List political group supports ...   \n",
       "1       1  When did the decline of coal start? It started...   \n",
       "2       2  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3       0  Health care reform legislation is likely to ma...   \n",
       "4       1  The economic turnaround started at the end of ...   \n",
       "5       3  The Chicago Bears have had more starting quart...   \n",
       "6       4  Jim Dunnam has not lived in the district he re...   \n",
       "7       1  \"I'm the only person on this stage who has wor...   \n",
       "8       1  However, it took $19.5 million in Oregon Lotte...   \n",
       "9       2  Says GOP primary opponents Glenn Grothman and ...   \n",
       "10      2  For the first time in history, the share of th...   \n",
       "11      1  Since 2000, nearly 12 million Americans have s...   \n",
       "12      0  When Mitt Romney was governor of Massachusetts...   \n",
       "13      2  The economy bled $24 billion due to the govern...   \n",
       "14      4  Most of the (Affordable Care Act) has already ...   \n",
       "15      1  In this last election in November, ... 63 perc...   \n",
       "16      3  \"McCain opposed a requirement that the governm...   \n",
       "17      4  U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...   \n",
       "18      1  Water rates in Manila, Philippines, were raise...   \n",
       "19      2  Almost 100,000 people left Puerto Rico last year.   \n",
       "20      0  Women and men both are making less when you ad...   \n",
       "21      2  The United States has the highest corporate ta...   \n",
       "22      2  We just had the best year for the auto industr...   \n",
       "23      1  Says Scott Walker favors cutting up to 350,000...   \n",
       "24      4  Says Mitt Romney wants to get rid of Planned P...   \n",
       "25      0              I dont know who (Jonathan Gruber) is.   \n",
       "26      2  Hate crimes against American Muslims and mosqu...   \n",
       "27      1  Rick Perry has never lost an election and rema...   \n",
       "28      0  ISIS supporter tweeted at 10:34 a.m. Shooting ...   \n",
       "29      2  Youth unemployment in minority communities is ...   \n",
       "30      3           Says Paul Ryan is still endorsing Trump.   \n",
       "31      4  If you look at states that are right to work, ...   \n",
       "32      0  What (the Obama administration is) going to co...   \n",
       "33      2  We cut business taxes so today 70 percent of o...   \n",
       "34      2  Says Mark Pryor votes with Obama 93 percent of...   \n",
       "35      3  We have a federal government that thinks they ...   \n",
       "36      3  Austin is a city that has basically doubled in...   \n",
       "37      3  The nuclear test conducted in our nation this ...   \n",
       "38      5  In the case of a catastrophic event, the Atlan...   \n",
       "39      3  Under President George W. Bush, we added $4.9 ...   \n",
       "40      0  Says a U.S. Supreme Court justice suggested th...   \n",
       "41      1  Says Marco Rubio skipped 18 defense votes incl...   \n",
       "42      5  Rep. David Cicilline is responsible for the fe...   \n",
       "43      5  Says Ohio budget item later signed into law by...   \n",
       "44      0  \"We have a director of homeland security who c...   \n",
       "45      1  African-American youth unemployment is 51 perc...   \n",
       "46      5  Obamacare will provide insurance to all non-U....   \n",
       "47      0  President Barack Obama took exactly none of hi...   \n",
       "48      5  It was under Barack Obama and Hillary Clinton ...   \n",
       "49      3  Hillary Clinton in 2005 co-sponsored legislati...   \n",
       "\n",
       "    barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "0                  0.0           1.0               0.0                 0.0   \n",
       "1                  0.0           0.0               1.0                 1.0   \n",
       "2                 70.0          71.0             160.0               163.0   \n",
       "3                  7.0          19.0               3.0                 5.0   \n",
       "4                 15.0           9.0              20.0                19.0   \n",
       "5                  0.0           3.0               2.0                 5.0   \n",
       "6                  3.0           1.0               1.0                 3.0   \n",
       "7                 70.0          71.0             160.0               163.0   \n",
       "8                  0.0           0.0               1.0                 0.0   \n",
       "9                  0.0           0.0               0.0                 1.0   \n",
       "10                 1.0           3.0               1.0                 3.0   \n",
       "11                18.0          12.0              22.0                41.0   \n",
       "12                34.0          32.0              58.0                33.0   \n",
       "13                 0.0           0.0               2.0                 4.0   \n",
       "14                 7.0           6.0               3.0                 5.0   \n",
       "15                18.0          12.0              22.0                41.0   \n",
       "16                70.0          71.0             160.0               163.0   \n",
       "17                18.0           9.0               8.0                 5.0   \n",
       "18                 3.0           4.0               4.0                 3.0   \n",
       "19                 0.0           1.0               0.0                 1.0   \n",
       "20                 0.0           4.0               1.0                 2.0   \n",
       "21                 2.0           1.0               1.0                 1.0   \n",
       "22                40.0          29.0              69.0                76.0   \n",
       "23                 3.0           3.0               3.0                 1.0   \n",
       "24                 1.0           0.0               0.0                 0.0   \n",
       "25                 3.0           7.0              11.0                 2.0   \n",
       "26                40.0          29.0              69.0                76.0   \n",
       "27                 0.0           0.0               2.0                 0.0   \n",
       "28                 0.0           1.0               1.0                 0.0   \n",
       "29                 0.0           0.0               0.0                 1.0   \n",
       "30                40.0          29.0              69.0                76.0   \n",
       "31                 1.0           0.0               0.0                 0.0   \n",
       "32                 1.0           1.0               0.0                 0.0   \n",
       "33                28.0          23.0              38.0                34.0   \n",
       "34                 3.0           4.0               2.0                 3.0   \n",
       "35                36.0          33.0              15.0                19.0   \n",
       "36                 1.0           0.0               4.0                 1.0   \n",
       "37                 0.0           0.0               0.0                 0.0   \n",
       "38                 0.0           0.0               0.0                 0.0   \n",
       "39                 2.0           1.0               1.0                 4.0   \n",
       "40                33.0          24.0              32.0                35.0   \n",
       "41                 0.0           1.0               1.0                 0.0   \n",
       "42                18.0           9.0               8.0                 5.0   \n",
       "43                 6.0           6.0               4.0                 6.0   \n",
       "44                 1.0           1.0               1.0                 3.0   \n",
       "45                18.0          12.0              22.0                41.0   \n",
       "46                11.0          43.0               8.0                 5.0   \n",
       "47                13.0          22.0              11.0                 4.0   \n",
       "48                 0.0           0.0               0.0                 0.0   \n",
       "49                 7.0          19.0               3.0                 5.0   \n",
       "\n",
       "    pants_on_fire_counts  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    9.0  \n",
       "3                   44.0  \n",
       "4                    2.0  \n",
       "5                    1.0  \n",
       "6                    1.0  \n",
       "7                    9.0  \n",
       "8                    1.0  \n",
       "9                    0.0  \n",
       "10                   0.0  \n",
       "11                   0.0  \n",
       "12                  19.0  \n",
       "13                   0.0  \n",
       "14                   1.0  \n",
       "15                   0.0  \n",
       "16                   9.0  \n",
       "17                   8.0  \n",
       "18                   1.0  \n",
       "19                   0.0  \n",
       "20                   0.0  \n",
       "21                   0.0  \n",
       "22                   7.0  \n",
       "23                   1.0  \n",
       "24                   0.0  \n",
       "25                   3.0  \n",
       "26                   7.0  \n",
       "27                   2.0  \n",
       "28                   0.0  \n",
       "29                   1.0  \n",
       "30                   7.0  \n",
       "31                   0.0  \n",
       "32                   0.0  \n",
       "33                   7.0  \n",
       "34                   1.0  \n",
       "35                   8.0  \n",
       "36                   0.0  \n",
       "37                   0.0  \n",
       "38                   1.0  \n",
       "39                   0.0  \n",
       "40                   5.0  \n",
       "41                   0.0  \n",
       "42                   8.0  \n",
       "43                   1.0  \n",
       "44                   0.0  \n",
       "45                   0.0  \n",
       "46                 105.0  \n",
       "47                   2.0  \n",
       "48                   1.0  \n",
       "49                  44.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Over the past five years the federal governmen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Says that Tennessee law requires that schools ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Says Vice President Joe Biden \"admits that the...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Donald Trump is against marriage equality. He ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>We know that more than half of Hillary Clinton...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>We know there are more Democrats in Georgia th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>PolitiFact Texas says Congressman Edwards atta...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Denali is the Kenyan word for black power.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Says 57 percent of federal spending goes to th...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>On residency requirements for public workers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>Says the unemployment rate for college graduat...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Unfortunately we have documented instances whe...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>A recent Gallup poll found that 72 percent of ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Each year, 18,000 people die in America becau...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Ronald Reagan faced an even worse recession\" ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>There have not been any public safety issues i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>Says Mitt Romney was one of the first national...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>The number of illegal immigrants could be 3 mi...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>Marijuana is less toxic than alcohol.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>Says Charlie Crist is embroiled in a fraud cas...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>Now, there was a time when someone like Scalia...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>I was gone when there was a red line against S...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Tim Kaine hiked tuition as governor, but now c...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>Contends that President Obama literally said (...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>Active duty males in the military are twice as...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>Its been since 1888 that a Senate of a differe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Rosemary Lehmberg, the Travis County D.A...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>On which team hes rooting for in the World Ser...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>Tom Ganley has two Fs from the Better Business...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>The United States has a low voter turnout rate.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>Says Thomas Jefferson said, You might be able ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>Because of the federal health care law, 300,00...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>In Massachusetts, Scott Brown pushed for a law...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>The Fed created $1.2 trillion out of nothing, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>Texas families have kept more than $10 billion...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>Pre-existing conditions are covered under my (...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>Greg Abbott activated the state guard to monit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>Says he won the second debate with Hillary Cli...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>Says bag litter increased after San Francisco ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>In 1993, Newt Gingrich first advocated for the...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>Says as a result of the national health care r...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>\"You said you would vote against the Patriot A...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>The federal minimum wage is worth about 20 per...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>A proposed tax to fund transportation projects...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>A salesclerk at Hobby Lobby who needs contrace...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          statement  \\\n",
       "0       3  Building a wall on the U.S.-Mexico border will...   \n",
       "1       0  Wisconsin is on pace to double the number of l...   \n",
       "2       0  Says John McCain has done nothing to help the ...   \n",
       "3       1  Suzanne Bonamici supports a plan that will cut...   \n",
       "4       5  When asked by a reporter whether hes at the ce...   \n",
       "5       3  Over the past five years the federal governmen...   \n",
       "6       3  Says that Tennessee law requires that schools ...   \n",
       "7       4  Says Vice President Joe Biden \"admits that the...   \n",
       "8       3  Donald Trump is against marriage equality. He ...   \n",
       "9       4  We know that more than half of Hillary Clinton...   \n",
       "10      4  We know there are more Democrats in Georgia th...   \n",
       "11      4  PolitiFact Texas says Congressman Edwards atta...   \n",
       "12      5         Denali is the Kenyan word for black power.   \n",
       "13      0  Says 57 percent of federal spending goes to th...   \n",
       "14      1       On residency requirements for public workers   \n",
       "15      3  Says the unemployment rate for college graduat...   \n",
       "16      5  Unfortunately we have documented instances whe...   \n",
       "17      1  A recent Gallup poll found that 72 percent of ...   \n",
       "18      3  \"Each year, 18,000 people die in America becau...   \n",
       "19      0  \"Ronald Reagan faced an even worse recession\" ...   \n",
       "20      2  There have not been any public safety issues i...   \n",
       "21      1  Says Mitt Romney was one of the first national...   \n",
       "22      5  The number of illegal immigrants could be 3 mi...   \n",
       "23      2              Marijuana is less toxic than alcohol.   \n",
       "24      0  Says Charlie Crist is embroiled in a fraud cas...   \n",
       "25      3  Now, there was a time when someone like Scalia...   \n",
       "26      4  I was gone when there was a red line against S...   \n",
       "27      1  Tim Kaine hiked tuition as governor, but now c...   \n",
       "28      3  Contends that President Obama literally said (...   \n",
       "29      2  Active duty males in the military are twice as...   \n",
       "30      0  Its been since 1888 that a Senate of a differe...   \n",
       "31      0  Under Rosemary Lehmberg, the Travis County D.A...   \n",
       "32      1  On which team hes rooting for in the World Ser...   \n",
       "33      1  Tom Ganley has two Fs from the Better Business...   \n",
       "34      3    The United States has a low voter turnout rate.   \n",
       "35      1  Says Thomas Jefferson said, You might be able ...   \n",
       "36      4  Because of the federal health care law, 300,00...   \n",
       "37      2  In Massachusetts, Scott Brown pushed for a law...   \n",
       "38      3  The Fed created $1.2 trillion out of nothing, ...   \n",
       "39      3  Texas families have kept more than $10 billion...   \n",
       "40      4  Pre-existing conditions are covered under my (...   \n",
       "41      1  Greg Abbott activated the state guard to monit...   \n",
       "42      5  Says he won the second debate with Hillary Cli...   \n",
       "43      4  Says bag litter increased after San Francisco ...   \n",
       "44      2  In 1993, Newt Gingrich first advocated for the...   \n",
       "45      4  Says as a result of the national health care r...   \n",
       "46      1  \"You said you would vote against the Patriot A...   \n",
       "47      2  The federal minimum wage is worth about 20 per...   \n",
       "48      0  A proposed tax to fund transportation projects...   \n",
       "49      4  A salesclerk at Hobby Lobby who needs contrace...   \n",
       "\n",
       "    barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "0                 30.0          30.0              42.0                23.0   \n",
       "1                  2.0           1.0               0.0                 0.0   \n",
       "2                 63.0         114.0              51.0                37.0   \n",
       "3                  1.0           1.0               3.0                 1.0   \n",
       "4                  5.0           7.0               2.0                 2.0   \n",
       "5                  1.0           2.0               1.0                 1.0   \n",
       "6                  0.0           0.0               0.0                 0.0   \n",
       "7                 13.0          22.0              11.0                 4.0   \n",
       "8                  0.0           0.0               0.0                 0.0   \n",
       "9                  8.0          10.0              12.0                 5.0   \n",
       "10                 1.0           0.0               0.0                 0.0   \n",
       "11                 2.0           0.0               0.0                 0.0   \n",
       "12                 5.0           5.0               0.0                 3.0   \n",
       "13                14.0          18.0              15.0                11.0   \n",
       "14                 3.0           5.0               4.0                 4.0   \n",
       "15                12.0          16.0              13.0                 7.0   \n",
       "16                 0.0           0.0               0.0                 0.0   \n",
       "17                 2.0           2.0               1.0                 0.0   \n",
       "18                40.0          29.0              69.0                76.0   \n",
       "19                 9.0          19.0               9.0                 6.0   \n",
       "20                 0.0           1.0               0.0                 1.0   \n",
       "21                33.0          24.0              32.0                35.0   \n",
       "22                63.0         114.0              51.0                37.0   \n",
       "23                 0.0           0.0               0.0                 1.0   \n",
       "24                10.0           6.0               6.0                 6.0   \n",
       "25                 2.0           2.0               4.0                 2.0   \n",
       "26                40.0          29.0              69.0                76.0   \n",
       "27                 6.0           6.0              11.0                 5.0   \n",
       "28                 8.0          10.0              12.0                 5.0   \n",
       "29                 0.0           0.0               2.0                 1.0   \n",
       "30                 4.0           1.0               0.0                 0.0   \n",
       "31                 9.0          19.0               9.0                 6.0   \n",
       "32                70.0          71.0             160.0               163.0   \n",
       "33                11.0           8.0               5.0                 1.0   \n",
       "34                 0.0           0.0               0.0                 0.0   \n",
       "35                 4.0          11.0               5.0                 3.0   \n",
       "36                28.0          23.0              38.0                34.0   \n",
       "37                 3.0           0.0               4.0                 2.0   \n",
       "38                 1.0           3.0               4.0                 6.0   \n",
       "39                 1.0           0.0               0.0                 1.0   \n",
       "40                34.0          32.0              58.0                33.0   \n",
       "41                 0.0           0.0               2.0                 4.0   \n",
       "42                63.0         114.0              51.0                37.0   \n",
       "43                 1.0           0.0               0.0                 0.0   \n",
       "44                 8.0          22.0               6.0                 4.0   \n",
       "45                 1.0           3.0               1.0                 3.0   \n",
       "46                40.0          29.0              69.0                76.0   \n",
       "47                70.0          71.0             160.0               163.0   \n",
       "48                 0.0           1.0               1.0                 0.0   \n",
       "49                40.0          29.0              69.0                76.0   \n",
       "\n",
       "    pants_on_fire_counts  \n",
       "0                   18.0  \n",
       "1                    0.0  \n",
       "2                   61.0  \n",
       "3                    1.0  \n",
       "4                    7.0  \n",
       "5                    0.0  \n",
       "6                    0.0  \n",
       "7                    2.0  \n",
       "8                    0.0  \n",
       "9                    0.0  \n",
       "10                   0.0  \n",
       "11                   0.0  \n",
       "12                  15.0  \n",
       "13                  36.0  \n",
       "14                   2.0  \n",
       "15                   5.0  \n",
       "16                   1.0  \n",
       "17                   0.0  \n",
       "18                   7.0  \n",
       "19                   6.0  \n",
       "20                   0.0  \n",
       "21                   5.0  \n",
       "22                  61.0  \n",
       "23                   0.0  \n",
       "24                   4.0  \n",
       "25                   0.0  \n",
       "26                   7.0  \n",
       "27                   2.0  \n",
       "28                   0.0  \n",
       "29                   0.0  \n",
       "30                   0.0  \n",
       "31                   6.0  \n",
       "32                   9.0  \n",
       "33                   9.0  \n",
       "34                   0.0  \n",
       "35                   3.0  \n",
       "36                   7.0  \n",
       "37                   0.0  \n",
       "38                   0.0  \n",
       "39                   0.0  \n",
       "40                  19.0  \n",
       "41                   0.0  \n",
       "42                  61.0  \n",
       "43                   0.0  \n",
       "44                  16.0  \n",
       "45                   0.0  \n",
       "46                   7.0  \n",
       "47                   9.0  \n",
       "48                   0.0  \n",
       "49                   7.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Says when armed civilians stop mass shootings ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Says Tennessee is providing millions of dollar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>The health care reform plan would set limits s...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Says Donald Trump started his career back in 1...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Bill White has a long history of trying to lim...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>John McCains chief economic adviser during the...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Says 21,000 Wisconsin residents got jobs in 20...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>State revenue projections have missed the mark...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>The median income of a middle class family wen...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Every citizen is entitled to the freedom of s...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Rick Perry has advocated abandoning Social Sec...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Two thirds to three quarters of people without...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>Congress has spent 66 of the first 100 days of...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Mark Sharpe has lowered property taxes by 17 p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Says Iowa Gov. Terry Branstad chartered a plan...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>If you dont buy cigarettes at your local super...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>Says President Barack Obama has said that ever...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>Georgia has had more bank failures than any o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>Bank of America could create 878,300 jobs with...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>Thom Tillis cut almost $500 million from educa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>If people work and make more money, they lose ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>We are poised to get rid of over 1,000 more re...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>A flight from Atlanta to Houston was canceled ...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>Administrative employees at colleges and unive...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>Private prison systems are calculating how man...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>Amendment 1 protects Florida seniors from scam...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>\"If Barack Obama would apply for a job with th...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>We have more kids take the SAT than any other ...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>Walker says hes for lower taxes. But Milwaukee...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>Says he did not say Republicans would filibust...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>Worldwide credit card transactions, the credit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>In the month of January, Canada created more n...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>Under his leadership, more people in Wisconsin...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>Charlie Crist attacks me for positions he held...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>Says Donald Trumps only economic agenda is imp...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>The loan guarantee program that helped Solyndr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>Says President Obama just granted all of Congr...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>Bill McCollumhas \"recovered $200 million in Me...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>Despite the U.S. spending $10 billion on Iraqs...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>Tim Kaine urged$500 billion in Medicare cuts.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>Over 3 million Americans are employed in the g...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Because of the steps we took, there are about...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>Says that In 2009, I saved ratepayers around $...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>The military has spent $500 million enforcing ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>Were. . . keeping and creating jobs in our sta...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          statement  \\\n",
       "0       4  We have less Americans working now than in the...   \n",
       "1       5  When Obama was sworn into office, he DID NOT u...   \n",
       "2       0  Says Having organizations parading as being so...   \n",
       "3       1     Says nearly half of Oregons children are poor.   \n",
       "4       1  On attacks by Republicans that various program...   \n",
       "5       0  Says when armed civilians stop mass shootings ...   \n",
       "6       3  Says Tennessee is providing millions of dollar...   \n",
       "7       0  The health care reform plan would set limits s...   \n",
       "8       3  Says Donald Trump started his career back in 1...   \n",
       "9       1  Bill White has a long history of trying to lim...   \n",
       "10      1  John McCains chief economic adviser during the...   \n",
       "11      0  Says 21,000 Wisconsin residents got jobs in 20...   \n",
       "12      1  State revenue projections have missed the mark...   \n",
       "13      3  The median income of a middle class family wen...   \n",
       "14      4  \"Every citizen is entitled to the freedom of s...   \n",
       "15      1  Rick Perry has advocated abandoning Social Sec...   \n",
       "16      1  Two thirds to three quarters of people without...   \n",
       "17      2  Congress has spent 66 of the first 100 days of...   \n",
       "18      4  Mark Sharpe has lowered property taxes by 17 p...   \n",
       "19      5  Says Iowa Gov. Terry Branstad chartered a plan...   \n",
       "20      1  If you dont buy cigarettes at your local super...   \n",
       "21      5  Says President Barack Obama has said that ever...   \n",
       "22      3  Georgia has had more bank failures than any o...   \n",
       "23      5  Bank of America could create 878,300 jobs with...   \n",
       "24      1  Thom Tillis cut almost $500 million from educa...   \n",
       "25      4  If people work and make more money, they lose ...   \n",
       "26      2  We are poised to get rid of over 1,000 more re...   \n",
       "27      5  A flight from Atlanta to Houston was canceled ...   \n",
       "28      2  Administrative employees at colleges and unive...   \n",
       "29      5  Private prison systems are calculating how man...   \n",
       "30      0  Amendment 1 protects Florida seniors from scam...   \n",
       "31      0  \"If Barack Obama would apply for a job with th...   \n",
       "32      4  We have more kids take the SAT than any other ...   \n",
       "33      4  Walker says hes for lower taxes. But Milwaukee...   \n",
       "34      0  Says he did not say Republicans would filibust...   \n",
       "35      2  Worldwide credit card transactions, the credit...   \n",
       "36      3  In the month of January, Canada created more n...   \n",
       "37      1  Under his leadership, more people in Wisconsin...   \n",
       "38      4  Charlie Crist attacks me for positions he held...   \n",
       "39      1  Says Donald Trumps only economic agenda is imp...   \n",
       "40      2  The loan guarantee program that helped Solyndr...   \n",
       "41      0  Says President Obama just granted all of Congr...   \n",
       "42      3  Bill McCollumhas \"recovered $200 million in Me...   \n",
       "43      4  Despite the U.S. spending $10 billion on Iraqs...   \n",
       "44      0      Tim Kaine urged$500 billion in Medicare cuts.   \n",
       "45      3  Over 3 million Americans are employed in the g...   \n",
       "46      1  \"Because of the steps we took, there are about...   \n",
       "47      2  Says that In 2009, I saved ratepayers around $...   \n",
       "48      2  The military has spent $500 million enforcing ...   \n",
       "49      3  Were. . . keeping and creating jobs in our sta...   \n",
       "\n",
       "    barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
       "0                  1.0           0.0               1.0                 0.0   \n",
       "1                 11.0          43.0               8.0                 5.0   \n",
       "2                  0.0           1.0               1.0                 1.0   \n",
       "3                  0.0           1.0               1.0                 1.0   \n",
       "4                 70.0          71.0             160.0               163.0   \n",
       "5                  1.0           1.0               0.0                 1.0   \n",
       "6                  0.0           0.0               0.0                 0.0   \n",
       "7                  4.0           5.0               4.0                 2.0   \n",
       "8                 40.0          29.0              69.0                76.0   \n",
       "9                  3.0           1.0               1.0                 3.0   \n",
       "10                 8.0           3.0              15.0                15.0   \n",
       "11                 1.0           1.0               1.0                 1.0   \n",
       "12                 0.0           0.0               1.0                 0.0   \n",
       "13                11.0          10.0              21.0                16.0   \n",
       "14                 8.0           8.0              10.0                 5.0   \n",
       "15                 0.0           0.0               1.0                 0.0   \n",
       "16                 1.0           0.0               2.0                 0.0   \n",
       "17                 0.0           0.0               1.0                 1.0   \n",
       "18                 1.0           0.0               0.0                 0.0   \n",
       "19                11.0          43.0               8.0                 5.0   \n",
       "20                 0.0           0.0               1.0                 0.0   \n",
       "21                 9.0          11.0              10.0                 7.0   \n",
       "22                 1.0           1.0               3.0                 0.0   \n",
       "23                14.0          18.0              15.0                11.0   \n",
       "24                 1.0           0.0               3.0                 2.0   \n",
       "25                33.0          24.0              32.0                35.0   \n",
       "26                28.0          23.0              38.0                34.0   \n",
       "27                14.0          18.0              15.0                11.0   \n",
       "28                33.0          24.0              32.0                35.0   \n",
       "29                 0.0           1.0               0.0                 1.0   \n",
       "30                 0.0           1.0               0.0                 0.0   \n",
       "31                11.0          43.0               8.0                 5.0   \n",
       "32                30.0          30.0              42.0                23.0   \n",
       "33                 2.0           5.0               8.0                 5.0   \n",
       "34                 0.0           2.0               4.0                 3.0   \n",
       "35                 0.0           0.0               0.0                 1.0   \n",
       "36                34.0          32.0              58.0                33.0   \n",
       "37                26.0          41.0              32.0                40.0   \n",
       "38                33.0          24.0              32.0                35.0   \n",
       "39                36.0          33.0              15.0                19.0   \n",
       "40                 1.0           0.0               0.0                 2.0   \n",
       "41                36.0          33.0              15.0                19.0   \n",
       "42                17.0           5.0              17.0                24.0   \n",
       "43                 1.0           0.0               0.0                 0.0   \n",
       "44                 5.0           5.0               4.0                 0.0   \n",
       "45                 5.0           5.0               7.0                 4.0   \n",
       "46                70.0          71.0             160.0               163.0   \n",
       "47                 1.0           1.0               0.0                 2.0   \n",
       "48                 1.0           0.0               1.0                 1.0   \n",
       "49                 9.0           8.0              10.0                18.0   \n",
       "\n",
       "    pants_on_fire_counts  \n",
       "0                    0.0  \n",
       "1                  105.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    9.0  \n",
       "5                    0.0  \n",
       "6                    0.0  \n",
       "7                    0.0  \n",
       "8                    7.0  \n",
       "9                    1.0  \n",
       "10                   0.0  \n",
       "11                   0.0  \n",
       "12                   0.0  \n",
       "13                   4.0  \n",
       "14                   5.0  \n",
       "15                   0.0  \n",
       "16                   0.0  \n",
       "17                   0.0  \n",
       "18                   0.0  \n",
       "19                 105.0  \n",
       "20                   0.0  \n",
       "21                   3.0  \n",
       "22                   0.0  \n",
       "23                  36.0  \n",
       "24                   0.0  \n",
       "25                   5.0  \n",
       "26                   7.0  \n",
       "27                  36.0  \n",
       "28                   5.0  \n",
       "29                   1.0  \n",
       "30                   0.0  \n",
       "31                 105.0  \n",
       "32                  18.0  \n",
       "33                   3.0  \n",
       "34                   0.0  \n",
       "35                   0.0  \n",
       "36                  19.0  \n",
       "37                  11.0  \n",
       "38                   5.0  \n",
       "39                   8.0  \n",
       "40                   0.0  \n",
       "41                   8.0  \n",
       "42                   2.0  \n",
       "43                   0.0  \n",
       "44                   0.0  \n",
       "45                   0.0  \n",
       "46                   9.0  \n",
       "47                   0.0  \n",
       "48                   0.0  \n",
       "49                   3.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop specified columns from each dataset\n",
    "columns_to_drop = ['id', 'subject', 'speaker', 'job_title', 'state_info', 'party_affiliation', 'context']\n",
    "\n",
    "ds_train = ds_train.drop(columns=columns_to_drop)\n",
    "ds_test = ds_test.drop(columns=columns_to_drop) \n",
    "ds_validation = ds_validation.drop(columns=columns_to_drop)\n",
    "\n",
    "# Display results\n",
    "print(\"Training Dataset:\")\n",
    "display(ds_train.head(50))\n",
    "print(\"\\nTest Dataset:\") \n",
    "display(ds_test.head(50))\n",
    "print(\"\\nValidation Dataset:\")\n",
    "display(ds_validation.head(50))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  false_counts  \\\n",
       "0      0  Says the Annies List political group supports ...           1.0   \n",
       "1      1  When did the decline of coal start? It started...           0.0   \n",
       "2      3  Hillary Clinton agrees with John McCain \"by vo...         150.0   \n",
       "3      0  Health care reform legislation is likely to ma...          70.0   \n",
       "4      1  The economic turnaround started at the end of ...          26.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  \n",
       "0               0.0                 0.0  \n",
       "1               1.0                 1.0  \n",
       "2             160.0               163.0  \n",
       "3               3.0                 5.0  \n",
       "4              20.0                19.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>238.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  false_counts  \\\n",
       "0      3  Building a wall on the U.S.-Mexico border will...          78.0   \n",
       "1      0  Wisconsin is on pace to double the number of l...           3.0   \n",
       "2      0  Says John McCain has done nothing to help the ...         238.0   \n",
       "3      1  Suzanne Bonamici supports a plan that will cut...           3.0   \n",
       "4      0  When asked by a reporter whether hes at the ce...          19.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  \n",
       "0              42.0                23.0  \n",
       "1               0.0                 0.0  \n",
       "2              51.0                37.0  \n",
       "3               3.0                 1.0  \n",
       "4               2.0                 2.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          statement  false_counts  \\\n",
       "0      0  We have less Americans working now than in the...           1.0   \n",
       "1      0  When Obama was sworn into office, he DID NOT u...         159.0   \n",
       "2      0  Says Having organizations parading as being so...           1.0   \n",
       "3      1     Says nearly half of Oregons children are poor.           1.0   \n",
       "4      1  On attacks by Republicans that various program...         150.0   \n",
       "\n",
       "   half_true_counts  mostly_true_counts  \n",
       "0               1.0                 0.0  \n",
       "1               8.0                 5.0  \n",
       "2               1.0                 1.0  \n",
       "3               1.0                 1.0  \n",
       "4             160.0               163.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def new_false(ds_train, ds_test, ds_validation):\n",
    "    \"\"\"\n",
    "    Combines the 'false_counts' and 'pants_on_fire_counts' columns into a single 'false_counts' column,\n",
    "    then drops the 'pants_on_fire_counts' column from each dataset.\n",
    "\n",
    "    Parameters:\n",
    "        ds_train (pd.DataFrame): Training dataset\n",
    "        ds_test (pd.DataFrame): Test dataset\n",
    "        ds_validation (pd.DataFrame): Validation dataset\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated (ds_train, ds_test, ds_validation) DataFrames\n",
    "    \"\"\"\n",
    "\n",
    "    #Quick note. We need to combine the data for the two columns in the label column as well. This will make it so that we can get equal sample sizes for each label.\n",
    "\n",
    "    # Combine false_counts and pants_on_fire_counts into a single 'false_counts' column\n",
    "    for ds in [ds_train, ds_test, ds_validation]:\n",
    "        ds['false_counts'] = ds['false_counts'] + ds['pants_on_fire_counts']\n",
    "\n",
    "        ds.drop('pants_on_fire_counts', axis=1, inplace=True)\n",
    "    return ds_train, ds_test, ds_validation\n",
    "\n",
    "def merge_columns(df, col_to_merge, col_to_keep, merge_label_value, keep_label_value):\n",
    "    \"\"\"\n",
    "    Merges one column's data into another and updates corresponding labels.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        col_to_merge (str): Name of column to be merged\n",
    "        col_to_keep (str): Name of column to merge into\n",
    "        merge_label_value (int): Label value associated with col_to_merge \n",
    "        keep_label_value (int): Label value associated with col_to_keep\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with merged columns and updated labels\n",
    "    \"\"\"\n",
    "    # Create copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Add values from col_to_merge into col_to_keep\n",
    "    df[col_to_keep] = df[col_to_keep] + df[col_to_merge]\n",
    "    \n",
    "    # Update labels - change merge_label_value to keep_label_value\n",
    "    df.loc[df['label'] == merge_label_value, 'label'] = keep_label_value\n",
    "    \n",
    "    # Drop the merged column\n",
    "    df.drop(col_to_merge, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#False = 0\n",
    "#Half-True = 1\n",
    "#Mostly-True / true = 3, 2\n",
    "#Barely-True = 4\n",
    "#Pants-On-Fire = 5\n",
    "\n",
    "# Update label 2 to 3 in all datasets. \n",
    "# #This is because true and mostly true are the same thing and they were combined into 1 without updating the labes.\n",
    "ds_train.loc[ds_train['label'] == 2, 'label'] = 3\n",
    "ds_test.loc[ds_test['label'] == 2, 'label'] = 3 \n",
    "ds_validation.loc[ds_validation['label'] == 2, 'label'] = 3\n",
    "\n",
    "#Merge pants on fire counts into false counts\n",
    "ds_train = merge_columns(ds_train, 'pants_on_fire_counts', 'false_counts', 5, 0)\n",
    "ds_test = merge_columns(ds_test, 'pants_on_fire_counts', 'false_counts', 5, 0)\n",
    "ds_validation = merge_columns(ds_validation, 'pants_on_fire_counts', 'false_counts', 5, 0)\n",
    "\n",
    "#Merge barely true counts into false counts\n",
    "ds_train = merge_columns(ds_train, 'barely_true_counts', 'false_counts', 4, 0)\n",
    "ds_test = merge_columns(ds_test, 'barely_true_counts', 'false_counts', 4, 0)\n",
    "ds_validation = merge_columns(ds_validation, 'barely_true_counts', 'false_counts', 4, 0)\n",
    "\n",
    "display(ds_train.head())\n",
    "display(ds_test.head())\n",
    "display(ds_validation.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data and Model ready\n",
    "## Load model_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelHelper\n",
    "model_helper = ModelHelper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after balancing:\n",
      "\n",
      "Training set:\n",
      "label\n",
      "0    2123\n",
      "1    2123\n",
      "3    2123\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set:\n",
      "label\n",
      "3    267\n",
      "0    267\n",
      "1    267\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation set:\n",
      "label\n",
      "0    248\n",
      "1    248\n",
      "3    248\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get balanced dataset by sampling equal number of records for each label\n",
    "def balance_dataset(df):\n",
    "    \"\"\"\n",
    "    Balance dataset by sampling equal number of records for each unique label.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with 'label' column\n",
    "        \n",
    "    Returns:\n",
    "        Balanced DataFrame with equal samples per label\n",
    "    \"\"\"\n",
    "    # Find minimum count across labels\n",
    "    min_count = df['label'].value_counts().min()\n",
    "    \n",
    "    # Sample equal number of records for each label\n",
    "    balanced_dfs = []\n",
    "    for label in df['label'].unique():\n",
    "        label_df = df[df['label'] == label].sample(n=min_count, random_state=42)\n",
    "        balanced_dfs.append(label_df)\n",
    "    \n",
    "    # Combine balanced samples\n",
    "    return pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "# Balance each dataset\n",
    "ds_train = balance_dataset(ds_train)\n",
    "ds_test = balance_dataset(ds_test) \n",
    "ds_validation = balance_dataset(ds_validation)\n",
    "\n",
    "# Display class distribution after balancing\n",
    "print(\"\\nClass distribution after balancing:\")\n",
    "print(\"\\nTraining set:\")\n",
    "print(ds_train['label'].value_counts())\n",
    "print(\"\\nTest set:\")\n",
    "print(ds_test['label'].value_counts())\n",
    "print(\"\\nValidation set:\") \n",
    "print(ds_validation['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vectorizor and start preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create Vectorizer\n",
    "model_helper.create_vectorizer(ds_train['statement'], max_sequence_length=60)\n",
    "\n",
    "# Preprocess text data\n",
    "train_sequences = model_helper.preprocess_text(ds_train['statement'].tolist())\n",
    "test_sequences = model_helper.preprocess_text(ds_test['statement'].tolist())\n",
    "val_sequences = model_helper.preprocess_text(ds_validation['statement'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sequence Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get truthfulness columns\n",
    "truthfulness_columns = model_helper.truthfulness_columns\n",
    "truthfulness_columns.remove('pants_on_fire_counts')\n",
    "truthfulness_columns.remove('barely_true_counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw count values for training\n",
    "train_labels = model_helper.normalize_counts(ds_train)\n",
    "test_labels = model_helper.normalize_counts(ds_test)\n",
    "val_labels = model_helper.normalize_counts(ds_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create text classification model\n",
    "model = model_helper.create_text_classification_model(\n",
    "    num_classes=len(truthfulness_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset, val_dataset, test_dataset = model_helper.prepare_datasets(\n",
    "    train_sequences=train_sequences,\n",
    "    train_labels=train_labels,\n",
    "    val_sequences=val_sequences,\n",
    "    val_labels=val_labels,\n",
    "    test_sequences=test_sequences,\n",
    "    test_labels=test_labels,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14640), started 6 days, 14:31:55 ago. (Use '!kill 14640' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a010c5e085f9132\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a010c5e085f9132\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:From c:\\Users\\matth\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "200/200 [==============================] - 2s 5ms/step - loss: 1.8665 - accuracy: 0.4447 - categorical_accuracy: 0.4447 - auc: 0.5709 - precision: 0.8450 - recall: 0.2485 - val_loss: 1.9203 - val_accuracy: 0.3616 - val_categorical_accuracy: 0.3616 - val_auc: 0.5231 - val_precision: 0.8066 - val_recall: 0.1629 - lr: 9.9902e-05\n",
      "Epoch 2/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7020 - accuracy: 0.4995 - categorical_accuracy: 0.4995 - auc: 0.6113 - precision: 0.8855 - recall: 0.2076 - val_loss: 1.8666 - val_accuracy: 0.3750 - val_categorical_accuracy: 0.3750 - val_auc: 0.5061 - val_precision: 0.7762 - val_recall: 0.1199 - lr: 9.9608e-05\n",
      "Epoch 3/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6395 - accuracy: 0.5298 - categorical_accuracy: 0.5298 - auc: 0.6344 - precision: 0.9022 - recall: 0.1995 - val_loss: 1.8083 - val_accuracy: 0.4140 - val_categorical_accuracy: 0.4140 - val_auc: 0.5045 - val_precision: 0.7788 - val_recall: 0.0943 - lr: 9.9117e-05\n",
      "Epoch 4/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5994 - accuracy: 0.5429 - categorical_accuracy: 0.5429 - auc: 0.6511 - precision: 0.9077 - recall: 0.2041 - val_loss: 1.7934 - val_accuracy: 0.3723 - val_categorical_accuracy: 0.3723 - val_auc: 0.5057 - val_precision: 0.7739 - val_recall: 0.0993 - lr: 9.8433e-05\n",
      "Epoch 5/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5693 - accuracy: 0.5533 - categorical_accuracy: 0.5533 - auc: 0.6596 - precision: 0.9123 - recall: 0.2089 - val_loss: 1.7625 - val_accuracy: 0.4046 - val_categorical_accuracy: 0.4046 - val_auc: 0.5106 - val_precision: 0.7530 - val_recall: 0.1037 - lr: 9.7558e-05\n",
      "Epoch 6/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5500 - accuracy: 0.5462 - categorical_accuracy: 0.5462 - auc: 0.6584 - precision: 0.9078 - recall: 0.2228 - val_loss: 1.7430 - val_accuracy: 0.3871 - val_categorical_accuracy: 0.3871 - val_auc: 0.5131 - val_precision: 0.7406 - val_recall: 0.1099 - lr: 9.6495e-05\n",
      "Epoch 7/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5364 - accuracy: 0.5509 - categorical_accuracy: 0.5509 - auc: 0.6571 - precision: 0.9002 - recall: 0.2319 - val_loss: 1.6968 - val_accuracy: 0.3965 - val_categorical_accuracy: 0.3965 - val_auc: 0.5118 - val_precision: 0.7525 - val_recall: 0.0831 - lr: 9.5249e-05\n",
      "Epoch 8/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5266 - accuracy: 0.5371 - categorical_accuracy: 0.5371 - auc: 0.6478 - precision: 0.8942 - recall: 0.2365 - val_loss: 1.6828 - val_accuracy: 0.3468 - val_categorical_accuracy: 0.3468 - val_auc: 0.5138 - val_precision: 0.7277 - val_recall: 0.0820 - lr: 9.3824e-05\n",
      "Epoch 9/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.5148 - accuracy: 0.5274 - categorical_accuracy: 0.5274 - auc: 0.6425 - precision: 0.8858 - recall: 0.2398 - val_loss: 1.6732 - val_accuracy: 0.3495 - val_categorical_accuracy: 0.3495 - val_auc: 0.5104 - val_precision: 0.7113 - val_recall: 0.0948 - lr: 9.2226e-05\n",
      "Epoch 10/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4996 - accuracy: 0.5331 - categorical_accuracy: 0.5331 - auc: 0.6373 - precision: 0.8825 - recall: 0.2477 - val_loss: 1.6329 - val_accuracy: 0.3817 - val_categorical_accuracy: 0.3817 - val_auc: 0.5086 - val_precision: 0.7264 - val_recall: 0.0859 - lr: 9.0461e-05\n",
      "Epoch 11/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4808 - accuracy: 0.5255 - categorical_accuracy: 0.5255 - auc: 0.6397 - precision: 0.8839 - recall: 0.2503 - val_loss: 1.6197 - val_accuracy: 0.3737 - val_categorical_accuracy: 0.3737 - val_auc: 0.5129 - val_precision: 0.7206 - val_recall: 0.0993 - lr: 8.8537e-05\n",
      "Epoch 12/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4643 - accuracy: 0.5228 - categorical_accuracy: 0.5228 - auc: 0.6401 - precision: 0.8883 - recall: 0.2491 - val_loss: 1.5946 - val_accuracy: 0.3911 - val_categorical_accuracy: 0.3911 - val_auc: 0.5103 - val_precision: 0.7291 - val_recall: 0.1021 - lr: 8.6461e-05\n",
      "Epoch 13/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4405 - accuracy: 0.5283 - categorical_accuracy: 0.5283 - auc: 0.6346 - precision: 0.8906 - recall: 0.2556 - val_loss: 1.5352 - val_accuracy: 0.4583 - val_categorical_accuracy: 0.4583 - val_auc: 0.5020 - val_precision: 0.7866 - val_recall: 0.0719 - lr: 8.4240e-05\n",
      "Epoch 14/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4173 - accuracy: 0.5232 - categorical_accuracy: 0.5232 - auc: 0.6368 - precision: 0.8855 - recall: 0.2536 - val_loss: 1.5587 - val_accuracy: 0.3481 - val_categorical_accuracy: 0.3481 - val_auc: 0.5048 - val_precision: 0.7198 - val_recall: 0.0931 - lr: 8.1885e-05\n",
      "Epoch 15/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.4004 - accuracy: 0.5170 - categorical_accuracy: 0.5170 - auc: 0.6399 - precision: 0.8934 - recall: 0.2540 - val_loss: 1.5042 - val_accuracy: 0.3401 - val_categorical_accuracy: 0.3401 - val_auc: 0.5064 - val_precision: 0.7347 - val_recall: 0.0402 - lr: 7.9404e-05\n",
      "Epoch 16/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3769 - accuracy: 0.5108 - categorical_accuracy: 0.5108 - auc: 0.6356 - precision: 0.8896 - recall: 0.2497 - val_loss: 1.4840 - val_accuracy: 0.3656 - val_categorical_accuracy: 0.3656 - val_auc: 0.5087 - val_precision: 0.7054 - val_recall: 0.0441 - lr: 7.6807e-05\n",
      "Epoch 17/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3583 - accuracy: 0.5172 - categorical_accuracy: 0.5172 - auc: 0.6322 - precision: 0.8902 - recall: 0.2425 - val_loss: 1.4633 - val_accuracy: 0.4220 - val_categorical_accuracy: 0.4220 - val_auc: 0.5016 - val_precision: 0.7377 - val_recall: 0.0502 - lr: 7.4104e-05\n",
      "Epoch 18/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3280 - accuracy: 0.5158 - categorical_accuracy: 0.5158 - auc: 0.6347 - precision: 0.8836 - recall: 0.2347 - val_loss: 1.4579 - val_accuracy: 0.3333 - val_categorical_accuracy: 0.3333 - val_auc: 0.4933 - val_precision: 0.7451 - val_recall: 0.0424 - lr: 7.1306e-05\n",
      "Epoch 19/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.3075 - accuracy: 0.5060 - categorical_accuracy: 0.5060 - auc: 0.6326 - precision: 0.8887 - recall: 0.2321 - val_loss: 1.4511 - val_accuracy: 0.3038 - val_categorical_accuracy: 0.3038 - val_auc: 0.5028 - val_precision: 0.6565 - val_recall: 0.0480 - lr: 6.8424e-05\n",
      "Epoch 20/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2791 - accuracy: 0.5340 - categorical_accuracy: 0.5340 - auc: 0.6384 - precision: 0.8993 - recall: 0.2284 - val_loss: 1.4306 - val_accuracy: 0.3306 - val_categorical_accuracy: 0.3306 - val_auc: 0.4983 - val_precision: 0.7043 - val_recall: 0.0452 - lr: 6.5469e-05\n",
      "Epoch 21/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2568 - accuracy: 0.5224 - categorical_accuracy: 0.5224 - auc: 0.6434 - precision: 0.9090 - recall: 0.2228 - val_loss: 1.4370 - val_accuracy: 0.2782 - val_categorical_accuracy: 0.2782 - val_auc: 0.4972 - val_precision: 0.6919 - val_recall: 0.0664 - lr: 6.2453e-05\n",
      "Epoch 22/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2440 - accuracy: 0.5216 - categorical_accuracy: 0.5216 - auc: 0.6335 - precision: 0.8938 - recall: 0.2135 - val_loss: 1.4135 - val_accuracy: 0.3118 - val_categorical_accuracy: 0.3118 - val_auc: 0.4984 - val_precision: 0.6903 - val_recall: 0.0597 - lr: 5.9389e-05\n",
      "Epoch 23/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2215 - accuracy: 0.5216 - categorical_accuracy: 0.5216 - auc: 0.6378 - precision: 0.9032 - recall: 0.2117 - val_loss: 1.3597 - val_accuracy: 0.4879 - val_categorical_accuracy: 0.4879 - val_auc: 0.4952 - val_precision: 0.7500 - val_recall: 0.0318 - lr: 5.6287e-05\n",
      "Epoch 24/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.2075 - accuracy: 0.5244 - categorical_accuracy: 0.5244 - auc: 0.6464 - precision: 0.9038 - recall: 0.2120 - val_loss: 1.3725 - val_accuracy: 0.3306 - val_categorical_accuracy: 0.3306 - val_auc: 0.5011 - val_precision: 0.7439 - val_recall: 0.0340 - lr: 5.3160e-05\n",
      "Epoch 25/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1872 - accuracy: 0.5307 - categorical_accuracy: 0.5307 - auc: 0.6533 - precision: 0.9086 - recall: 0.2090 - val_loss: 1.3311 - val_accuracy: 0.5269 - val_categorical_accuracy: 0.5269 - val_auc: 0.4968 - val_precision: 0.8058 - val_recall: 0.0463 - lr: 5.0021e-05\n",
      "Epoch 26/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1770 - accuracy: 0.5511 - categorical_accuracy: 0.5511 - auc: 0.6494 - precision: 0.9138 - recall: 0.2023 - val_loss: 1.3104 - val_accuracy: 0.5874 - val_categorical_accuracy: 0.5874 - val_auc: 0.4979 - val_precision: 0.8413 - val_recall: 0.0591 - lr: 4.6881e-05\n",
      "Epoch 27/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1606 - accuracy: 0.5484 - categorical_accuracy: 0.5484 - auc: 0.6582 - precision: 0.9196 - recall: 0.2036 - val_loss: 1.3396 - val_accuracy: 0.3427 - val_categorical_accuracy: 0.3427 - val_auc: 0.4992 - val_precision: 0.7500 - val_recall: 0.0284 - lr: 4.3755e-05\n",
      "Epoch 28/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1520 - accuracy: 0.5456 - categorical_accuracy: 0.5456 - auc: 0.6568 - precision: 0.9183 - recall: 0.1972 - val_loss: 1.3189 - val_accuracy: 0.4234 - val_categorical_accuracy: 0.4234 - val_auc: 0.4925 - val_precision: 0.7119 - val_recall: 0.0234 - lr: 4.0652e-05\n",
      "Epoch 29/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1455 - accuracy: 0.5401 - categorical_accuracy: 0.5401 - auc: 0.6555 - precision: 0.9137 - recall: 0.1934 - val_loss: 1.3361 - val_accuracy: 0.3360 - val_categorical_accuracy: 0.3360 - val_auc: 0.4946 - val_precision: 0.7040 - val_recall: 0.0491 - lr: 3.7587e-05\n",
      "Epoch 30/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1391 - accuracy: 0.5444 - categorical_accuracy: 0.5444 - auc: 0.6549 - precision: 0.9208 - recall: 0.1960 - val_loss: 1.3205 - val_accuracy: 0.3199 - val_categorical_accuracy: 0.3199 - val_auc: 0.4924 - val_precision: 0.6849 - val_recall: 0.0279 - lr: 3.4571e-05\n",
      "Epoch 31/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1293 - accuracy: 0.5519 - categorical_accuracy: 0.5519 - auc: 0.6537 - precision: 0.9231 - recall: 0.1912 - val_loss: 1.3340 - val_accuracy: 0.2688 - val_categorical_accuracy: 0.2688 - val_auc: 0.4982 - val_precision: 0.7121 - val_recall: 0.0524 - lr: 3.1615e-05\n",
      "Epoch 32/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1218 - accuracy: 0.5506 - categorical_accuracy: 0.5506 - auc: 0.6589 - precision: 0.9157 - recall: 0.1891 - val_loss: 1.3291 - val_accuracy: 0.2473 - val_categorical_accuracy: 0.2473 - val_auc: 0.4958 - val_precision: 0.7167 - val_recall: 0.0480 - lr: 2.8732e-05\n",
      "Epoch 33/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1194 - accuracy: 0.5464 - categorical_accuracy: 0.5464 - auc: 0.6583 - precision: 0.9209 - recall: 0.1902 - val_loss: 1.2835 - val_accuracy: 0.4207 - val_categorical_accuracy: 0.4207 - val_auc: 0.5002 - val_precision: 0.7209 - val_recall: 0.0173 - lr: 2.5933e-05\n",
      "Epoch 34/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1133 - accuracy: 0.5539 - categorical_accuracy: 0.5539 - auc: 0.6552 - precision: 0.9233 - recall: 0.1852 - val_loss: 1.3129 - val_accuracy: 0.2876 - val_categorical_accuracy: 0.2876 - val_auc: 0.4956 - val_precision: 0.7234 - val_recall: 0.0379 - lr: 2.3230e-05\n",
      "Epoch 35/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1071 - accuracy: 0.5455 - categorical_accuracy: 0.5455 - auc: 0.6561 - precision: 0.9203 - recall: 0.1869 - val_loss: 1.2827 - val_accuracy: 0.3817 - val_categorical_accuracy: 0.3817 - val_auc: 0.4996 - val_precision: 0.7083 - val_recall: 0.0190 - lr: 2.0631e-05\n",
      "Epoch 36/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0995 - accuracy: 0.5519 - categorical_accuracy: 0.5519 - auc: 0.6598 - precision: 0.9225 - recall: 0.1872 - val_loss: 1.2719 - val_accuracy: 0.4516 - val_categorical_accuracy: 0.4516 - val_auc: 0.4986 - val_precision: 0.6800 - val_recall: 0.0190 - lr: 1.8149e-05\n",
      "Epoch 37/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0972 - accuracy: 0.5478 - categorical_accuracy: 0.5478 - auc: 0.6600 - precision: 0.9203 - recall: 0.1855 - val_loss: 1.2828 - val_accuracy: 0.3508 - val_categorical_accuracy: 0.3508 - val_auc: 0.5001 - val_precision: 0.7119 - val_recall: 0.0234 - lr: 1.5793e-05\n",
      "Epoch 38/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0994 - accuracy: 0.5429 - categorical_accuracy: 0.5429 - auc: 0.6530 - precision: 0.9226 - recall: 0.1795 - val_loss: 1.2880 - val_accuracy: 0.3360 - val_categorical_accuracy: 0.3360 - val_auc: 0.4972 - val_precision: 0.7200 - val_recall: 0.0301 - lr: 1.3571e-05\n",
      "Epoch 39/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0946 - accuracy: 0.5492 - categorical_accuracy: 0.5492 - auc: 0.6573 - precision: 0.9155 - recall: 0.1827 - val_loss: 1.2726 - val_accuracy: 0.3817 - val_categorical_accuracy: 0.3817 - val_auc: 0.4982 - val_precision: 0.7143 - val_recall: 0.0195 - lr: 1.1493e-05\n",
      "Epoch 40/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0924 - accuracy: 0.5448 - categorical_accuracy: 0.5448 - auc: 0.6539 - precision: 0.9165 - recall: 0.1748 - val_loss: 1.2911 - val_accuracy: 0.3132 - val_categorical_accuracy: 0.3132 - val_auc: 0.4925 - val_precision: 0.6915 - val_recall: 0.0363 - lr: 9.5674e-06\n",
      "Epoch 41/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0932 - accuracy: 0.5365 - categorical_accuracy: 0.5365 - auc: 0.6514 - precision: 0.9156 - recall: 0.1786 - val_loss: 1.2854 - val_accuracy: 0.3172 - val_categorical_accuracy: 0.3172 - val_auc: 0.4929 - val_precision: 0.7229 - val_recall: 0.0335 - lr: 7.8012e-06\n",
      "Epoch 42/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0970 - accuracy: 0.5426 - categorical_accuracy: 0.5426 - auc: 0.6466 - precision: 0.9186 - recall: 0.1766 - val_loss: 1.2841 - val_accuracy: 0.3159 - val_categorical_accuracy: 0.3159 - val_auc: 0.4926 - val_precision: 0.7333 - val_recall: 0.0307 - lr: 6.2016e-06\n",
      "Epoch 43/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0998 - accuracy: 0.5409 - categorical_accuracy: 0.5409 - auc: 0.6387 - precision: 0.9118 - recall: 0.1757 - val_loss: 1.2916 - val_accuracy: 0.2849 - val_categorical_accuracy: 0.2849 - val_auc: 0.4916 - val_precision: 0.7033 - val_recall: 0.0357 - lr: 4.7749e-06\n",
      "Epoch 44/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1050 - accuracy: 0.5192 - categorical_accuracy: 0.5192 - auc: 0.6232 - precision: 0.8959 - recall: 0.1641 - val_loss: 1.2767 - val_accuracy: 0.3481 - val_categorical_accuracy: 0.3481 - val_auc: 0.4917 - val_precision: 0.7121 - val_recall: 0.0262 - lr: 3.5266e-06\n",
      "Epoch 45/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1037 - accuracy: 0.5335 - categorical_accuracy: 0.5335 - auc: 0.6217 - precision: 0.8975 - recall: 0.1605 - val_loss: 1.2769 - val_accuracy: 0.3414 - val_categorical_accuracy: 0.3414 - val_auc: 0.4921 - val_precision: 0.6970 - val_recall: 0.0257 - lr: 2.4618e-06\n",
      "Epoch 46/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1139 - accuracy: 0.5211 - categorical_accuracy: 0.5211 - auc: 0.6068 - precision: 0.8863 - recall: 0.1414 - val_loss: 1.2571 - val_accuracy: 0.4368 - val_categorical_accuracy: 0.4368 - val_auc: 0.4955 - val_precision: 0.6977 - val_recall: 0.0167 - lr: 1.5846e-06\n",
      "Epoch 47/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1163 - accuracy: 0.5359 - categorical_accuracy: 0.5359 - auc: 0.5923 - precision: 0.8715 - recall: 0.1298 - val_loss: 1.2447 - val_accuracy: 0.5040 - val_categorical_accuracy: 0.5040 - val_auc: 0.4987 - val_precision: 0.6944 - val_recall: 0.0139 - lr: 8.9849e-07\n",
      "Epoch 48/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1188 - accuracy: 0.5381 - categorical_accuracy: 0.5381 - auc: 0.5889 - precision: 0.8730 - recall: 0.1178 - val_loss: 1.2376 - val_accuracy: 0.5551 - val_categorical_accuracy: 0.5551 - val_auc: 0.5005 - val_precision: 0.8070 - val_recall: 0.0257 - lr: 4.0620e-07\n",
      "Epoch 49/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1151 - accuracy: 0.5387 - categorical_accuracy: 0.5387 - auc: 0.5935 - precision: 0.8749 - recall: 0.1226 - val_loss: 1.2343 - val_accuracy: 0.5820 - val_categorical_accuracy: 0.5820 - val_auc: 0.5013 - val_precision: 0.8116 - val_recall: 0.0312 - lr: 1.0964e-07\n",
      "Epoch 50/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1151 - accuracy: 0.5455 - categorical_accuracy: 0.5455 - auc: 0.5918 - precision: 0.8784 - recall: 0.1248 - val_loss: 1.2335 - val_accuracy: 0.5954 - val_categorical_accuracy: 0.5954 - val_auc: 0.5014 - val_precision: 0.8052 - val_recall: 0.0346 - lr: 1.0003e-08\n",
      "Epoch 51/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0908 - accuracy: 0.5296 - categorical_accuracy: 0.5296 - auc: 0.6430 - precision: 0.9157 - recall: 0.1926 - val_loss: 1.2403 - val_accuracy: 0.4772 - val_categorical_accuracy: 0.4772 - val_auc: 0.5037 - val_precision: 0.7317 - val_recall: 0.0167 - lr: 8.9979e-05\n",
      "Epoch 52/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0666 - accuracy: 0.5591 - categorical_accuracy: 0.5591 - auc: 0.6596 - precision: 0.9237 - recall: 0.1847 - val_loss: 1.2174 - val_accuracy: 0.5470 - val_categorical_accuracy: 0.5470 - val_auc: 0.5056 - val_precision: 0.7941 - val_recall: 0.0452 - lr: 8.9913e-05\n",
      "Epoch 53/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0547 - accuracy: 0.5597 - categorical_accuracy: 0.5597 - auc: 0.6619 - precision: 0.9227 - recall: 0.1861 - val_loss: 1.2257 - val_accuracy: 0.5081 - val_categorical_accuracy: 0.5081 - val_auc: 0.5000 - val_precision: 0.7760 - val_recall: 0.0541 - lr: 8.9802e-05\n",
      "Epoch 54/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0413 - accuracy: 0.5564 - categorical_accuracy: 0.5564 - auc: 0.6616 - precision: 0.9288 - recall: 0.1842 - val_loss: 1.1988 - val_accuracy: 0.5269 - val_categorical_accuracy: 0.5269 - val_auc: 0.5048 - val_precision: 0.7581 - val_recall: 0.0262 - lr: 8.9647e-05\n",
      "Epoch 55/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0354 - accuracy: 0.5542 - categorical_accuracy: 0.5542 - auc: 0.6604 - precision: 0.9244 - recall: 0.1924 - val_loss: 1.2368 - val_accuracy: 0.2419 - val_categorical_accuracy: 0.2419 - val_auc: 0.5018 - val_precision: 0.6279 - val_recall: 0.0151 - lr: 8.9448e-05\n",
      "Epoch 56/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0251 - accuracy: 0.5462 - categorical_accuracy: 0.5462 - auc: 0.6620 - precision: 0.9325 - recall: 0.1848 - val_loss: 1.1755 - val_accuracy: 0.6116 - val_categorical_accuracy: 0.6116 - val_auc: 0.4991 - val_precision: 0.8623 - val_recall: 0.0664 - lr: 8.9205e-05\n",
      "Epoch 57/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0253 - accuracy: 0.5564 - categorical_accuracy: 0.5564 - auc: 0.6624 - precision: 0.9253 - recall: 0.1975 - val_loss: 1.1832 - val_accuracy: 0.5323 - val_categorical_accuracy: 0.5323 - val_auc: 0.4978 - val_precision: 0.8235 - val_recall: 0.0547 - lr: 8.8919e-05\n",
      "Epoch 58/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0216 - accuracy: 0.5536 - categorical_accuracy: 0.5536 - auc: 0.6543 - precision: 0.9251 - recall: 0.1950 - val_loss: 1.1959 - val_accuracy: 0.4113 - val_categorical_accuracy: 0.4113 - val_auc: 0.5001 - val_precision: 0.6981 - val_recall: 0.0206 - lr: 8.8589e-05\n",
      "Epoch 59/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0200 - accuracy: 0.5360 - categorical_accuracy: 0.5360 - auc: 0.6577 - precision: 0.9147 - recall: 0.1902 - val_loss: 1.2334 - val_accuracy: 0.2325 - val_categorical_accuracy: 0.2325 - val_auc: 0.5144 - val_precision: 0.7241 - val_recall: 0.0468 - lr: 8.8216e-05\n",
      "Epoch 60/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0193 - accuracy: 0.5417 - categorical_accuracy: 0.5417 - auc: 0.6548 - precision: 0.9163 - recall: 0.2000 - val_loss: 1.2242 - val_accuracy: 0.2661 - val_categorical_accuracy: 0.2661 - val_auc: 0.5066 - val_precision: 0.6692 - val_recall: 0.0485 - lr: 8.7801e-05\n",
      "Epoch 61/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0212 - accuracy: 0.5222 - categorical_accuracy: 0.5222 - auc: 0.6490 - precision: 0.9146 - recall: 0.1813 - val_loss: 1.2243 - val_accuracy: 0.2608 - val_categorical_accuracy: 0.2608 - val_auc: 0.5116 - val_precision: 0.6618 - val_recall: 0.0502 - lr: 8.7343e-05\n",
      "Epoch 62/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0140 - accuracy: 0.5396 - categorical_accuracy: 0.5396 - auc: 0.6525 - precision: 0.9145 - recall: 0.1919 - val_loss: 1.1980 - val_accuracy: 0.3306 - val_categorical_accuracy: 0.3306 - val_auc: 0.5063 - val_precision: 0.7160 - val_recall: 0.0323 - lr: 8.6844e-05\n",
      "Epoch 63/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0048 - accuracy: 0.5500 - categorical_accuracy: 0.5500 - auc: 0.6572 - precision: 0.9187 - recall: 0.1952 - val_loss: 1.1735 - val_accuracy: 0.5417 - val_categorical_accuracy: 0.5417 - val_auc: 0.4991 - val_precision: 0.7436 - val_recall: 0.0323 - lr: 8.6303e-05\n",
      "Epoch 64/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0061 - accuracy: 0.5555 - categorical_accuracy: 0.5555 - auc: 0.6528 - precision: 0.9188 - recall: 0.1993 - val_loss: 1.1472 - val_accuracy: 0.6035 - val_categorical_accuracy: 0.6035 - val_auc: 0.5121 - val_precision: 0.7544 - val_recall: 0.0240 - lr: 8.5722e-05\n",
      "Epoch 65/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0064 - accuracy: 0.5503 - categorical_accuracy: 0.5503 - auc: 0.6560 - precision: 0.9225 - recall: 0.2023 - val_loss: 1.1852 - val_accuracy: 0.3548 - val_categorical_accuracy: 0.3548 - val_auc: 0.5037 - val_precision: 0.6984 - val_recall: 0.0245 - lr: 8.5100e-05\n",
      "Epoch 66/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.0043 - accuracy: 0.5385 - categorical_accuracy: 0.5385 - auc: 0.6508 - precision: 0.9175 - recall: 0.2010 - val_loss: 1.3459 - val_accuracy: 0.1747 - val_categorical_accuracy: 0.1747 - val_auc: 0.5079 - val_precision: 0.7492 - val_recall: 0.2683 - lr: 8.4439e-05\n",
      "Epoch 67/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.0076 - accuracy: 0.5440 - categorical_accuracy: 0.5440 - auc: 0.6494 - precision: 0.9092 - recall: 0.2064 - val_loss: 1.2016 - val_accuracy: 0.2836 - val_categorical_accuracy: 0.2836 - val_auc: 0.5037 - val_precision: 0.7143 - val_recall: 0.0418 - lr: 8.3739e-05\n",
      "Epoch 68/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9926 - accuracy: 0.5517 - categorical_accuracy: 0.5517 - auc: 0.6555 - precision: 0.9280 - recall: 0.1923 - val_loss: 1.2252 - val_accuracy: 0.1828 - val_categorical_accuracy: 0.1828 - val_auc: 0.5128 - val_precision: 0.6531 - val_recall: 0.0178 - lr: 8.3000e-05\n",
      "Epoch 69/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9947 - accuracy: 0.5354 - categorical_accuracy: 0.5354 - auc: 0.6563 - precision: 0.9154 - recall: 0.1956 - val_loss: 1.1322 - val_accuracy: 0.6384 - val_categorical_accuracy: 0.6384 - val_auc: 0.4984 - val_precision: 0.8000 - val_recall: 0.0201 - lr: 8.2224e-05\n",
      "Epoch 70/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9808 - accuracy: 0.5544 - categorical_accuracy: 0.5544 - auc: 0.6642 - precision: 0.9336 - recall: 0.1920 - val_loss: 1.1253 - val_accuracy: 0.6519 - val_categorical_accuracy: 0.6519 - val_auc: 0.5084 - val_precision: 0.8763 - val_recall: 0.0474 - lr: 8.1412e-05\n",
      "Epoch 71/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9743 - accuracy: 0.5608 - categorical_accuracy: 0.5608 - auc: 0.6730 - precision: 0.9342 - recall: 0.1901 - val_loss: 1.3734 - val_accuracy: 0.1626 - val_categorical_accuracy: 0.1626 - val_auc: 0.5095 - val_precision: 0.7550 - val_recall: 0.2956 - lr: 8.0563e-05\n",
      "Epoch 72/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9926 - accuracy: 0.5367 - categorical_accuracy: 0.5367 - auc: 0.6473 - precision: 0.9202 - recall: 0.2023 - val_loss: 1.1498 - val_accuracy: 0.4906 - val_categorical_accuracy: 0.4906 - val_auc: 0.5052 - val_precision: 0.5926 - val_recall: 0.0089 - lr: 7.9680e-05\n",
      "Epoch 73/300\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9748 - accuracy: 0.5585 - categorical_accuracy: 0.5585 - auc: 0.6710 - precision: 0.9327 - recall: 0.2021 - val_loss: 1.1681 - val_accuracy: 0.5081 - val_categorical_accuracy: 0.5081 - val_auc: 0.4974 - val_precision: 0.7885 - val_recall: 0.0229 - lr: 7.8762e-05\n",
      "Epoch 74/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9735 - accuracy: 0.5659 - categorical_accuracy: 0.5659 - auc: 0.6656 - precision: 0.9355 - recall: 0.1991 - val_loss: 1.1776 - val_accuracy: 0.2917 - val_categorical_accuracy: 0.2917 - val_auc: 0.5087 - val_precision: 0.6481 - val_recall: 0.0195 - lr: 7.7811e-05\n",
      "Epoch 75/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9773 - accuracy: 0.5505 - categorical_accuracy: 0.5505 - auc: 0.6680 - precision: 0.9292 - recall: 0.1968 - val_loss: 1.1769 - val_accuracy: 0.2917 - val_categorical_accuracy: 0.2917 - val_auc: 0.5050 - val_precision: 0.6429 - val_recall: 0.0251 - lr: 7.6827e-05\n",
      "Epoch 76/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9774 - accuracy: 0.5610 - categorical_accuracy: 0.5610 - auc: 0.6638 - precision: 0.9263 - recall: 0.2011 - val_loss: 1.1471 - val_accuracy: 0.6371 - val_categorical_accuracy: 0.6371 - val_auc: 0.5074 - val_precision: 0.8544 - val_recall: 0.1244 - lr: 7.5812e-05\n",
      "Epoch 77/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9720 - accuracy: 0.5558 - categorical_accuracy: 0.5558 - auc: 0.6596 - precision: 0.9294 - recall: 0.1825 - val_loss: 1.1577 - val_accuracy: 0.2567 - val_categorical_accuracy: 0.2567 - val_auc: 0.4980 - val_precision: 0.7619 - val_recall: 0.0178 - lr: 7.4767e-05\n",
      "Epoch 78/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9687 - accuracy: 0.5569 - categorical_accuracy: 0.5569 - auc: 0.6624 - precision: 0.9332 - recall: 0.1928 - val_loss: 1.2222 - val_accuracy: 0.2056 - val_categorical_accuracy: 0.2056 - val_auc: 0.5073 - val_precision: 0.7095 - val_recall: 0.0954 - lr: 7.3692e-05\n",
      "Epoch 79/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9657 - accuracy: 0.5527 - categorical_accuracy: 0.5527 - auc: 0.6700 - precision: 0.9327 - recall: 0.1854 - val_loss: 1.1563 - val_accuracy: 0.2500 - val_categorical_accuracy: 0.2500 - val_auc: 0.5096 - val_precision: 0.7273 - val_recall: 0.0089 - lr: 7.2589e-05\n",
      "Epoch 80/300\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.9789 - accuracy: 0.5447 - categorical_accuracy: 0.5447 - auc: 0.6495 - precision: 0.9234 - recall: 0.1897 - val_loss: 1.1930 - val_accuracy: 0.2648 - val_categorical_accuracy: 0.2648 - val_auc: 0.5067 - val_precision: 0.6718 - val_recall: 0.0491 - lr: 7.1459e-05\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir models/logs/fit\n",
    "\n",
    "# Train the model using ModelHelper's train_model method\n",
    "history = model_helper.train_model(\n",
    "    model=model,\n",
    "    train_data=train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=300,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 1.1198 - accuracy: 0.6742 - categorical_accuracy: 0.6742 - auc: 0.5183 - precision: 0.9135 - recall: 0.0498\n",
      "[1.119826316833496, 0.6741573214530945, 0.6741573214530945, 0.5183225274085999, 0.9134615659713745, 0.049764275550842285]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = model.evaluate(test_dataset)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model_helper.save_model(model, \"text_classification_model_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Use Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.80787924e-03 -1.44528849e-02  6.46416424e-03 -2.56793685e-02\n",
      "  -9.65327397e-02  8.58551189e-02  6.98082447e-02  3.99074377e-03\n",
      "  -8.74180868e-02  2.87988503e-02  2.87528969e-02  1.01409713e-02\n",
      "   2.93969605e-02 -8.59811381e-02 -3.12866308e-02  7.26936832e-02\n",
      "   4.58125258e-03  8.62116888e-02  2.10175058e-03  1.01940013e-01\n",
      "   7.18423799e-02  4.75919712e-03 -9.46561049e-05  5.05877845e-02\n",
      "   1.56101644e-01  4.36919257e-02 -1.51563315e-02  2.40388163e-03\n",
      "  -1.58895310e-02 -2.51775812e-02 -1.06737919e-01  7.07412809e-02\n",
      "   4.94894832e-02  3.08563840e-02  2.91129984e-02 -3.40982117e-02\n",
      "   1.11657195e-01  4.70892824e-02 -6.71625230e-03  2.94581391e-02\n",
      "  -4.25266698e-02 -3.54633946e-03 -1.84288230e-02 -1.99071560e-02\n",
      "  -8.40682983e-02 -8.74066129e-02  5.21774963e-02 -1.68546159e-02\n",
      "   4.58840802e-02  2.17433758e-02 -6.76908568e-02  4.28052358e-02\n",
      "  -4.56975177e-02 -2.15390436e-02  2.67212316e-02 -1.36472238e-02\n",
      "   5.95129468e-03  8.63851160e-02  2.10052487e-02 -1.97168756e-02\n",
      "   1.13614928e-02 -7.40882158e-02 -4.86826850e-03 -4.10203375e-02\n",
      "   4.74912263e-02  1.97790246e-02 -2.54844539e-02 -2.54539941e-02\n",
      "  -1.00875743e-01 -3.24559696e-02  7.74060190e-02  3.55644152e-02\n",
      "   3.60606425e-02 -4.41351347e-02 -4.15929146e-02 -2.54299771e-02\n",
      "   2.59144269e-02  9.97828841e-02  2.47023851e-02 -5.32053038e-02\n",
      "  -3.03913392e-02 -6.45044297e-02 -3.00089829e-02  3.04775108e-02\n",
      "   2.26590876e-02  3.11912540e-02 -3.30706500e-02 -8.55620485e-03\n",
      "   9.77698416e-02  5.59805986e-03 -3.21980603e-02 -3.08516230e-02\n",
      "   5.29674031e-02 -8.34014936e-05 -1.36827692e-01 -5.64701855e-04\n",
      "  -2.26151366e-02 -5.05981185e-02  7.29595125e-02  8.11563283e-02\n",
      "  -4.45732698e-02  7.35438541e-02  7.91888833e-02 -8.04399513e-03\n",
      "   5.64965270e-02 -1.33524416e-02  8.16367418e-02  3.63839678e-02\n",
      "  -2.52702944e-02 -4.30326862e-03  6.32501468e-02 -1.81358233e-02\n",
      "  -4.86677736e-02  2.52714921e-02  1.24649378e-02 -7.28349909e-02\n",
      "   5.06964438e-02 -4.06837910e-02 -5.03948852e-02 -4.21512686e-02\n",
      "  -2.28825840e-03 -4.10881154e-02 -8.70722085e-02 -2.78281271e-02\n",
      "  -8.98407027e-03  2.32613813e-02 -3.11367121e-02  8.48703468e-33\n",
      "  -8.69430136e-03 -1.00875925e-02  1.03917502e-01  8.03878531e-02\n",
      "  -1.09626139e-02  6.99294731e-02 -4.84222779e-03  3.21942158e-02\n",
      "   1.75167508e-02 -4.37184311e-02  2.85164686e-03  2.49363557e-02\n",
      "   1.45712513e-02 -3.53305675e-02  4.30735983e-02 -4.75503914e-02\n",
      "  -1.21541053e-01 -6.06756890e-03  3.28565128e-02  3.72109003e-02\n",
      "   3.75833102e-02  2.96558533e-02  2.65982235e-03 -6.02332614e-02\n",
      "  -5.89765199e-02 -4.31454964e-02  7.11720288e-02 -8.55362322e-03\n",
      "  -3.01106200e-02  4.97582629e-02  7.27541223e-02  8.29466339e-03\n",
      "   9.00040939e-02 -4.94955182e-02  8.43963679e-03  9.10962094e-03\n",
      "   2.64840871e-02 -3.22102085e-02 -5.68740349e-03 -2.53543872e-02\n",
      "  -3.66960168e-02 -6.19153865e-02 -6.33224705e-03  7.89630711e-02\n",
      "  -9.05002281e-02 -2.35932972e-02  6.15361929e-02  6.21905457e-03\n",
      "   7.59215727e-02  4.80186492e-02 -5.01365885e-02  4.01865393e-02\n",
      "  -6.12934902e-02 -3.53846736e-02 -5.31219654e-02 -2.22593453e-02\n",
      "  -1.19259744e-03  1.80792958e-02 -2.82183266e-03  4.22932133e-02\n",
      "   5.33000566e-02  1.44053586e-02  4.99451458e-02 -7.67344143e-03\n",
      "  -7.88567290e-02  2.75330152e-02 -2.45353160e-03 -3.71607090e-03\n",
      "   2.00694837e-02  4.64915857e-02  2.97161322e-02 -3.81348990e-02\n",
      "   3.62603343e-03  1.02467306e-01 -3.38630565e-02  1.05056576e-01\n",
      "   1.56934336e-02 -2.78142281e-02 -5.53614348e-02 -4.65550795e-02\n",
      "   3.94237414e-02 -6.87384307e-02  3.22860442e-02  1.29611436e-02\n",
      "   1.15911201e-01  5.07804714e-02  3.55973281e-02 -1.00378931e-01\n",
      "  -2.52621318e-03 -2.74653174e-02  6.18899874e-02 -1.49929132e-02\n",
      "   8.32444429e-02 -1.00433432e-01 -1.03428364e-01 -7.92628567e-33\n",
      "  -9.25232023e-02  1.24962702e-02  4.81627602e-03 -5.96378371e-02\n",
      "   2.04673130e-02 -5.11252135e-02 -3.43741791e-04 -1.37166843e-01\n",
      "  -4.27424535e-02  3.84765561e-04 -1.61481351e-02 -5.31370491e-02\n",
      "   2.19196305e-02  1.98029224e-02  3.09379678e-02 -2.81003700e-03\n",
      "   8.64957646e-02 -6.46618381e-02 -5.46987839e-02 -9.35491920e-02\n",
      "  -4.46290895e-02  6.14789985e-02 -3.29558067e-02  1.39616445e-01\n",
      "  -1.00271434e-01  4.38610464e-02 -3.61036249e-02  2.04758607e-02\n",
      "   1.65209118e-02  1.86032206e-02 -1.80727127e-03 -6.87238052e-02\n",
      "  -1.63898654e-02  2.13362500e-02 -9.16789472e-02 -3.75746228e-02\n",
      "  -3.14064845e-02 -1.03159659e-01  5.66423908e-02 -7.03755245e-02\n",
      "  -8.13019369e-03 -9.60855260e-02 -1.16996840e-02  9.56855714e-03\n",
      "  -1.98917650e-02 -2.14092713e-02 -7.08636642e-02  8.46200343e-03\n",
      "   8.36855173e-03 -2.76264157e-02  3.19928639e-02  1.02515601e-01\n",
      "  -7.14282691e-02  9.92311612e-02 -5.03786234e-03  3.38161774e-02\n",
      "   4.24031243e-02 -7.34072924e-03  5.15478626e-02  6.04495890e-02\n",
      "  -8.16773474e-02  1.88765302e-02  1.89337153e-02  3.69185619e-02\n",
      "   3.22232768e-02 -6.15826435e-02 -5.19962702e-03 -1.26098067e-01\n",
      "  -2.40174066e-02 -2.89024990e-02 -5.81593020e-03  4.03790027e-02\n",
      "  -5.34722246e-02  4.60682400e-02 -8.89129341e-02  8.24407637e-02\n",
      "  -4.24355865e-02  4.70482046e-03 -2.38838345e-02 -1.53547274e-02\n",
      "   3.30894254e-02 -4.57459986e-02  1.70112234e-02 -1.19330473e-02\n",
      "  -6.60377219e-02 -1.77703593e-02  6.61385804e-02 -7.67567456e-02\n",
      "  -2.86203045e-02 -6.04644069e-04 -1.81209724e-02  1.66583643e-03\n",
      "   1.09622367e-02  1.51795074e-02  2.28642850e-04 -3.71085704e-08\n",
      "  -8.31353758e-03  1.25022460e-04 -3.03429794e-02  3.35219838e-02\n",
      "   2.27205567e-02 -7.73107726e-03 -5.43748587e-02  9.38131288e-02\n",
      "  -7.66236382e-03 -2.23431736e-03  2.29963828e-02  1.70469265e-02\n",
      "   1.98515337e-02  7.60079771e-02  9.42344964e-03 -1.84741169e-02\n",
      "   1.53545421e-02 -4.04079668e-02 -7.06517994e-02 -1.04121948e-02\n",
      "  -3.86155806e-02 -1.02596562e-02 -6.82087988e-03  5.96759208e-02\n",
      "   2.55043991e-02  2.85396762e-02 -1.65744610e-02  1.79695755e-01\n",
      "   7.88444504e-02 -4.65118624e-02  1.28747069e-03  1.71071123e-02\n",
      "  -6.08967841e-02  2.65735039e-03 -6.12265877e-02  2.37627029e-02\n",
      "  -9.90877859e-04  1.52336694e-02 -4.84543331e-02  2.00082269e-02\n",
      "   2.95267347e-02  3.06237210e-03 -6.40541986e-02  9.03525949e-02\n",
      "  -1.31257325e-02 -1.23560596e-02 -3.45345922e-02 -2.76839845e-02\n",
      "   7.02800229e-03 -1.00114100e-01  2.35807002e-02  3.11898477e-02\n",
      "   4.04712968e-02 -1.01443669e-02  1.20102474e-02 -4.17667031e-02\n",
      "  -9.32373628e-02 -1.76480657e-03 -1.47410901e-02  1.11326352e-01\n",
      "   3.44987889e-03 -1.91769619e-02  1.15963379e-02 -2.95077506e-02]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "[[0.4353583  0.25709248 0.3075492 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = model_helper.load_model(\"text_classification_model_final\")\n",
    "test_string = 'Barbara Buono by the numbers: As a Trenton politician, she voted to raise taxes 154 times. Under her, property taxes up 70 percent. Backed a 16 percent sales tax increase. Utilities, nursing homes, cell phones, parking lots, lottery wins, gyms She taxed them all. Architect of Corzines budget, she drove New Jersey $2 billion into debt. Barbara Buono by the numbers: taking New Jersey backwards.'\n",
    "print(model_helper.preprocess_text(test_string))\n",
    "prediction = loaded_model.predict(model_helper.preprocess_text(test_string))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use prepared test data to get Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 384), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))>\n",
      "26/26 [==============================] - 0s 2ms/step\n",
      "\n",
      "Sample predictions:\n",
      "Example 1:\n",
      "Predicted probabilities: [0.43882662 0.31933266 0.24184068]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 2:\n",
      "Predicted probabilities: [0.45658416 0.2490904  0.29432547]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 3:\n",
      "Predicted probabilities: [0.550378   0.17213032 0.27749166]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 4:\n",
      "Predicted probabilities: [0.47776264 0.31845286 0.20378453]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 5:\n",
      "Predicted probabilities: [0.4353775  0.261791   0.30283144]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 6:\n",
      "Predicted probabilities: [0.3908481  0.37031868 0.23883316]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 7:\n",
      "Predicted probabilities: [0.42929986 0.2669491  0.30375102]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 8:\n",
      "Predicted probabilities: [0.35180217 0.52618706 0.12201072]\n",
      "Predicted class: 1\n",
      "Actual class: 0\n",
      "\n",
      "Example 9:\n",
      "Predicted probabilities: [0.37007344 0.20939942 0.4205272 ]\n",
      "Predicted class: 2\n",
      "Actual class: 2\n",
      "\n",
      "Example 10:\n",
      "Predicted probabilities: [0.46045107 0.2552493  0.28429967]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 11:\n",
      "Predicted probabilities: [0.488888   0.31105974 0.20005226]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 12:\n",
      "Predicted probabilities: [0.29108322 0.31573647 0.3931803 ]\n",
      "Predicted class: 2\n",
      "Actual class: 1\n",
      "\n",
      "Example 13:\n",
      "Predicted probabilities: [0.47732556 0.30266678 0.22000772]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 14:\n",
      "Predicted probabilities: [0.354166   0.28849784 0.35733613]\n",
      "Predicted class: 2\n",
      "Actual class: 0\n",
      "\n",
      "Example 15:\n",
      "Predicted probabilities: [0.44734377 0.29705095 0.2556054 ]\n",
      "Predicted class: 0\n",
      "Actual class: 1\n",
      "\n",
      "Example 16:\n",
      "Predicted probabilities: [0.37103057 0.3096672  0.31930217]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 17:\n",
      "Predicted probabilities: [0.40831628 0.33163476 0.26004905]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 18:\n",
      "Predicted probabilities: [0.46982843 0.32051253 0.20965907]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 19:\n",
      "Predicted probabilities: [0.4749774  0.30663103 0.21839157]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 20:\n",
      "Predicted probabilities: [0.5525706  0.20027445 0.247155  ]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 21:\n",
      "Predicted probabilities: [0.31240574 0.40035418 0.2872401 ]\n",
      "Predicted class: 1\n",
      "Actual class: 2\n",
      "\n",
      "Example 22:\n",
      "Predicted probabilities: [0.46788514 0.2758288  0.256286  ]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 23:\n",
      "Predicted probabilities: [0.41839522 0.31321058 0.2683942 ]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 24:\n",
      "Predicted probabilities: [0.536762   0.25647452 0.20676343]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 25:\n",
      "Predicted probabilities: [0.5484171  0.2330379  0.21854503]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 26:\n",
      "Predicted probabilities: [0.43249753 0.23345734 0.33404505]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 27:\n",
      "Predicted probabilities: [0.36544532 0.3964935  0.23806117]\n",
      "Predicted class: 1\n",
      "Actual class: 0\n",
      "\n",
      "Example 28:\n",
      "Predicted probabilities: [0.3939365  0.31785333 0.28821012]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 29:\n",
      "Predicted probabilities: [0.35653582 0.36038643 0.2830778 ]\n",
      "Predicted class: 1\n",
      "Actual class: 0\n",
      "\n",
      "Example 30:\n",
      "Predicted probabilities: [0.47047114 0.29212216 0.23740669]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 31:\n",
      "Predicted probabilities: [0.38905406 0.37497264 0.2359732 ]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 32:\n",
      "Predicted probabilities: [0.43891966 0.32068962 0.2403907 ]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 33:\n",
      "Predicted probabilities: [0.4825113 0.2808629 0.2366258]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 34:\n",
      "Predicted probabilities: [0.39687043 0.32025972 0.28286985]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 35:\n",
      "Predicted probabilities: [0.46370238 0.29449543 0.24180216]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 36:\n",
      "Predicted probabilities: [0.38630313 0.27419755 0.3394993 ]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 37:\n",
      "Predicted probabilities: [0.42164105 0.2942092  0.28414968]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 38:\n",
      "Predicted probabilities: [0.43880895 0.34636456 0.21482651]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 39:\n",
      "Predicted probabilities: [0.1990072  0.4133009  0.38769194]\n",
      "Predicted class: 1\n",
      "Actual class: 2\n",
      "\n",
      "Example 40:\n",
      "Predicted probabilities: [0.37337014 0.27313012 0.35349974]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 41:\n",
      "Predicted probabilities: [0.49855953 0.20173153 0.29970893]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 42:\n",
      "Predicted probabilities: [0.44141814 0.27562612 0.28295574]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 43:\n",
      "Predicted probabilities: [0.3744358 0.2739431 0.3516211]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 44:\n",
      "Predicted probabilities: [0.41277385 0.29341596 0.2938102 ]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n",
      "Example 45:\n",
      "Predicted probabilities: [0.39972812 0.3352925  0.26497936]\n",
      "Predicted class: 0\n",
      "Actual class: 1\n",
      "\n",
      "Example 46:\n",
      "Predicted probabilities: [0.49293318 0.2743921  0.23267467]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 47:\n",
      "Predicted probabilities: [0.4144259  0.30505675 0.28051734]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 48:\n",
      "Predicted probabilities: [0.3861711  0.3178496  0.29597926]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 49:\n",
      "Predicted probabilities: [0.3942083  0.34899348 0.25679824]\n",
      "Predicted class: 0\n",
      "Actual class: 0\n",
      "\n",
      "Example 50:\n",
      "Predicted probabilities: [0.48709738 0.2578757  0.25502697]\n",
      "Predicted class: 0\n",
      "Actual class: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test dataset\n",
    "print(test_dataset)\n",
    "predictions = loaded_model.predict(test_dataset)\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(50):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Predicted probabilities: {predictions[i]}\")\n",
    "    print(f\"Predicted class: {predicted_classes[i]}\")\n",
    "    print(f\"Actual class: {np.argmax(test_labels[i])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_classification_model', 'text_classification_model_final']\n"
     ]
    }
   ],
   "source": [
    "models_list = model_helper.list_models()\n",
    "print(models_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
